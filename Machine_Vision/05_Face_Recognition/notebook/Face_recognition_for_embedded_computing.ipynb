{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition for embedded computing\n",
    "\n",
    "## Author:\n",
    "## [Dr. Rahul Remanan](https://www.linkedin.com/in/rahulremanan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set variables for notebook behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_mode = False\n",
    "videoFile_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_source = './Barack_Obama_2004_DNC_Speech_CSPAN.mp4'\n",
    "save_path = './proc_vid.avi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if webcam_mode:\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "elif videoFile_mode:\n",
    "    video_capture = cv2.VideoCapture(video_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-14 10:52:19--  https://ichef.bbci.co.uk/news/320/cpsprodpb/E225/production/_93339875_obamalaughing.jpg\n",
      "Resolving ichef.bbci.co.uk (ichef.bbci.co.uk)... 23.78.209.21, 2600:141b:7000:1bc::f33, 2600:141b:7000:18b::f33\n",
      "Connecting to ichef.bbci.co.uk (ichef.bbci.co.uk)|23.78.209.21|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7444 (7.3K) [image/jpeg]\n",
      "Saving to: ‘obama.jpg’\n",
      "\n",
      "obama.jpg           100%[===================>]   7.27K  --.-KB/s    in 0s      \n",
      "\n",
      "2019-06-14 10:52:19 (71.4 MB/s) - ‘obama.jpg’ saved [7444/7444]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://ichef.bbci.co.uk/news/320/cpsprodpb/E225/production/_93339875_obamalaughing.jpg -O obama.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-14 10:52:19--  https://thehill.com/sites/default/files/styles/thumb_small_article/public/bidenjoe_050719getty.jpg?itok=5jH57P6x\n",
      "Resolving thehill.com (thehill.com)... 151.101.194.217, 151.101.66.217, 151.101.130.217, ...\n",
      "Connecting to thehill.com (thehill.com)|151.101.194.217|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23944 (23K) [image/jpeg]\n",
      "Saving to: ‘biden.jpg’\n",
      "\n",
      "biden.jpg           100%[===================>]  23.38K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2019-06-14 10:52:19 (1.39 MB/s) - ‘biden.jpg’ saved [23944/23944]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://thehill.com/sites/default/files/styles/thumb_small_article/public/bidenjoe_050719getty.jpg?itok=5jH57P6x -O biden.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate face recognition embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_image = face_recognition.load_image_file(\"obama.jpg\")\n",
    "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "\n",
    "biden_image = face_recognition.load_image_file(\"biden.jpg\")\n",
    "biden_face_encoding = face_recognition.face_encodings(biden_image)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create arrays of face encodings and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodings = [obama_face_encoding,\n",
    "                        biden_face_encoding]\n",
    "\n",
    "known_face_names = [\"Barack Obama\",\n",
    "                    \"Joe Biden\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_rate = 15\n",
    "num_proc_frames = None\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second using video.get(cv2.CAP_PROP_FPS) : 29.970050362180636\n",
      "Source image width: 480\n",
      "Source image height: 360\n"
     ]
    }
   ],
   "source": [
    "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "print (\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
    "img_w, img_h = int(video_capture.get(3)),int(video_capture.get(4))\n",
    "print (\"Source image width: \"+ str(img_w))\n",
    "print (\"Source image height: \"+ str(img_h))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')#cv2.VideoWriter_fourcc(*'XVID')#\n",
    "video_writer = cv2.VideoWriter(save_path, \n",
    "                               fourcc, \n",
    "                               fps, \n",
    "                               (img_w,img_h), \n",
    "                               True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "frame_number = 0\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    frame_number += 1\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    try:\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "    except:\n",
    "        break\n",
    "\n",
    "    if frame_number % detection_rate == 0:\n",
    "        # Find all the faces and face enqcodings in the frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        # Loop through each face in this frame of video\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # If a match was found in known_face_encodings, just use the first one.\n",
    "            # if True in matches:\n",
    "            #     first_match_index = matches.index(True)\n",
    "            #     name = known_face_names[first_match_index]\n",
    "\n",
    "            # Or instead, use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Draw a label with a name below the face\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "            if verbose:\n",
    "                print (\"Processing frame {} / {}\".format(frame_number, length))\n",
    "    try:\n",
    "        video_writer.write(frame)\n",
    "        if verbose:\n",
    "            print(\"Writing frame {} / {}\".format(frame_number, length))\n",
    "    except:\n",
    "        print(\"Failed writing frame {} / {}\".format(frame_number, length))\n",
    "    if num_proc_frames != None and frame_number == num_proc_frames:\n",
    "        break\n",
    "        \n",
    "end = time.time()\n",
    "print ('Video processed in: {} seconds ...'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i ./Barack_Obama_2004_DNC_Speech_CSPAN.mp4 -ab 320000 -ac 2 -ar 44100 -vn ./audio.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ffmpeg -y -i ./output_vid.avi -i ./audio.wav -shortest -c:v copy -c:a aac -b:a 256k  ./proc_vid_audio.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!HandBrakeCLI -i ./proc_vid_audio.mp4 -o ./output_vid.mp4 -e x264 -q 22 -r 15 -B 64 -X 480 -O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi threaded face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! lscpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from multiprocessing import Process, Manager, cpu_count\n",
    "import time\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_mode = False\n",
    "videoFile_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_source = './Barack_Obama_2004_DNC_Speech_CSPAN.mp4'\n",
    "save_path = './output_vid.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if webcam_mode:\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "elif videoFile_mode:\n",
    "    video_capture = cv2.VideoCapture(video_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_id(current_id):\n",
    "    if current_id == worker_num:\n",
    "        return 1\n",
    "    else:\n",
    "        return current_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_id(current_id):\n",
    "    if current_id == 1:\n",
    "        return worker_num\n",
    "    else:\n",
    "        return current_id - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture(read_frame_list):\n",
    "    # Get a reference to webcam #0 (the default one)\n",
    "    video_capture = cv2.VideoCapture(video_source)\n",
    "    # video_capture.set(3, 640)  # Width of the frames in the video stream.\n",
    "    # video_capture.set(4, 480)  # Height of the frames in the video stream.\n",
    "    # video_capture.set(5, 30) # Frame rate.\n",
    "    print(\"Width: %d, Height: %d, FPS: %d\" % (video_capture.get(3), video_capture.get(4), video_capture.get(5)))\n",
    "\n",
    "    while not Global.is_exit:\n",
    "        # If it's time to read a frame\n",
    "        if Global.buff_num != next_id(Global.read_num):\n",
    "            # Grab a single frame of video\n",
    "            ret, frame = video_capture.read()\n",
    "            read_frame_list[Global.buff_num] = frame\n",
    "            Global.buff_num = next_id(Global.buff_num)\n",
    "        else:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "    # Release webcam\n",
    "    video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(worker_id, read_frame_list, write_frame_list):\n",
    "    known_face_encodings = Global.known_face_encodings\n",
    "    known_face_names = Global.known_face_names\n",
    "    while not Global.is_exit:\n",
    "\n",
    "        # Wait to read\n",
    "        while Global.read_num != worker_id or Global.read_num != prev_id(Global.buff_num):\n",
    "            time.sleep(0.001)\n",
    "\n",
    "        # Delay to make the video look smoother\n",
    "        #time.sleep(Global.frame_delay)\n",
    "\n",
    "        # Read a single frame from frame list\n",
    "        frame_process = read_frame_list[worker_id]\n",
    "\n",
    "        # Expect next worker to read frame\n",
    "        Global.read_num = next_id(Global.read_num)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_frame = frame_process[:, :, ::-1]\n",
    "        \n",
    "        Global.frame_num +=1\n",
    "        if Global.frame_num % Global.sampling_rate == 0:\n",
    "            # Find all the faces and face encodings in the frame of video, cost most time\n",
    "            face_locations = face_recognition.face_locations(rgb_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "            # Loop through each face in this frame of video\n",
    "            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "                # See if the face is a match for the known face(s)\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "                name = \"Unknown\"\n",
    "\n",
    "                # If a match was found in known_face_encodings, just use the first one.\n",
    "                if True in matches:\n",
    "                    first_match_index = matches.index(True)\n",
    "                    name = known_face_names[first_match_index]\n",
    "\n",
    "                # Draw a box around the face\n",
    "                cv2.rectangle(frame_process, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "                # Draw a label with a name below the face\n",
    "                cv2.rectangle(frame_process, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame_process, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "                if Global.verbose:\n",
    "                    print ('Processing frame: {} ...'.format(Global.frame_num))\n",
    "\n",
    "        # Wait to write\n",
    "        while Global.write_num != worker_id:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        # Send frame to global\n",
    "        write_frame_list[worker_id] = frame_process\n",
    "\n",
    "        # Expect next worker to write frame\n",
    "        Global.write_num = next_id(Global.write_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "Global = Manager().Namespace()\n",
    "Global.buff_num = 1\n",
    "Global.read_num = 1\n",
    "Global.write_num = 1\n",
    "Global.frame_delay = 0\n",
    "Global.is_exit = False\n",
    "Global.frame_num = 0\n",
    "Global.sampling_rate = 15\n",
    "Global.verbose = False\n",
    "read_frame_list = Manager().dict()\n",
    "write_frame_list = Manager().dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of workers (subprocess use to process frames)\n",
    "worker_num = 2#cpu_count()\n",
    "print ('Using: {} out of: {} available CPU cores ...'.format(worker_num,\n",
    "                                                             cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subprocess list\n",
    "p = []\n",
    "\n",
    "# Create a subprocess to capture frames\n",
    "p.append(Process(target=capture, args=(read_frame_list,)))\n",
    "p[0].start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample picture and learn how to recognize it.\n",
    "obama_image = face_recognition.load_image_file(\"obama.jpg\")\n",
    "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "\n",
    "# Load a second sample picture and learn how to recognize it.\n",
    "biden_image = face_recognition.load_image_file(\"biden.jpg\")\n",
    "biden_face_encoding = face_recognition.face_encodings(biden_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays of known face encodings and their names\n",
    "Global.known_face_encodings = [\n",
    "    obama_face_encoding,\n",
    "    biden_face_encoding\n",
    "]\n",
    "Global.known_face_names = [\n",
    "    \"Barack Obama\",\n",
    "    \"Joe Biden\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create workers\n",
    "for worker_id in range(1, worker_num + 1):\n",
    "    p.append(Process(target=process, args=(worker_id, read_frame_list, write_frame_list)))\n",
    "    p[worker_id].start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_ = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "print (\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps_))\n",
    "img_w, img_h = int(video_capture.get(3)),int(video_capture.get(4))\n",
    "print (\"Source image width: \"+ str(img_w))\n",
    "print (\"Source image height: \"+ str(img_h))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')#cv2.VideoWriter_fourcc(*'XVID')#\n",
    "video_writer = cv2.VideoWriter(save_path, \n",
    "                               fourcc, \n",
    "                               fps_, \n",
    "                               (img_w,img_h), \n",
    "                               True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start to show video\n",
    "last_num = 1\n",
    "fps_list = []\n",
    "tmp_time = time.time()\n",
    "while not Global.is_exit:\n",
    "    while Global.write_num != last_num:\n",
    "        last_num = int(Global.write_num)\n",
    "\n",
    "        # Calculate fps\n",
    "        delay = time.time() - tmp_time\n",
    "        tmp_time = time.time()\n",
    "        fps_list.append(delay)\n",
    "        if len(fps_list) > 5 * worker_num:\n",
    "            fps_list.pop(0)\n",
    "        fps = len(fps_list) / numpy.sum(fps_list)\n",
    "        if Global.verbose:\n",
    "            print(\"fps: %.2f\" % fps)\n",
    "\n",
    "        # Calculate frame delay, in order to make the video look smoother.\n",
    "        # When fps is higher, should use a smaller ratio, or fps will be limited in a lower value.\n",
    "        # Larger ratio can make the video look smoother, but fps will hard to become higher.\n",
    "        # Smaller ratio can make fps higher, but the video looks not too smoother.\n",
    "        # The ratios below are tested many times.\n",
    "#         if fps < 6:\n",
    "#             Global.frame_delay = (1 / fps) * 0.75\n",
    "#         elif fps < 20:\n",
    "#             Global.frame_delay = (1 / fps) * 0.5\n",
    "#         elif fps < 30:\n",
    "#             Global.frame_delay = (1 / fps) * 0.25\n",
    "#         else:\n",
    "#             Global.frame_delay = 0\n",
    "\n",
    "        # Display the resulting image\n",
    "        #print (write_frame_list[prev_id(Global.write_num)])\n",
    "        video_writer.write(write_frame_list[prev_id(Global.write_num)])\n",
    "print ('Video processed in: {} seconds ...'.format(time.time()-tmp_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
