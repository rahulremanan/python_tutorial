{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Monte_Carlo_Dropout_MNIST_Example",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9dv1t4DdM4i",
        "colab_type": "text"
      },
      "source": [
        "# Monte Carlo Dropout -- Example Notebook\n",
        "\n",
        "## [Launch this notebook in Google CoLab](https://colab.research.google.com/github/rahulremanan/python_tutorial/blob/master/Machine_Vision/07_Bayesian_deep_learning/notebook/Monte_Carlo_Dropout_MNIST_Example.ipynb)\n",
        "\n",
        "This notebook is a modified fork of the Bayesian MNIST classifier implementation [here](https://github.com/homaralex/mc-dropout-mnist/blob/master/models.py).\n",
        "\n",
        "In this notebook, a Bayesian LeNet model is trained using the [MNIST data](http://yann.lecun.com/exdb/mnist/).\n",
        "\n",
        "A Bayesian inference function generates the mean prediction accuracy and the associated prediction uncertainty of the trained model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8jDtN6S4HyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c0158d2e-d838-48fa-c0ea-7aae3e2f797d"
      },
      "source": [
        "! wget https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/Machine_Vision/07_Bayesian_deep_learning/weights/bayesianLeNet.h5 -O ./bayesianLeNet.h5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-20 14:12:42--  https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/Machine_Vision/07_Bayesian_deep_learning/weights/bayesianLeNet.h5\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1750208 (1.7M) [application/octet-stream]\n",
            "Saving to: ‘./bayesianLeNet.h5’\n",
            "\n",
            "\r./bayesianLeNet.h5    0%[                    ]       0  --.-KB/s               \r./bayesianLeNet.h5  100%[===================>]   1.67M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-05-20 14:12:42 (19.2 MB/s) - ‘./bayesianLeNet.h5’ saved [1750208/1750208]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLnTqjMojRVt",
        "colab_type": "text"
      },
      "source": [
        "## Build a Bayesian network\n",
        "\n",
        "The network used in this example is a LeNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgj9IWnrd3sM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39f0483e-e0e9-461d-bb64-3099926a325b"
      },
      "source": [
        "from keras import Input, Model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln7P1vcAeM47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LeNet(input_shape, num_classes):\n",
        "  \n",
        "  inp = Input(shape=input_shape)\n",
        "  \n",
        "  x = Conv2D(filters=20, kernel_size=5, strides=1)(inp)\n",
        "  x = MaxPool2D(pool_size=2, strides=2)(x)\n",
        "  \n",
        "  x = Conv2D(filters=50, kernel_size=5, strides=1)(x)\n",
        "  x = MaxPool2D(pool_size=2, strides=2)(x)\n",
        "  x = Flatten()(x)\n",
        "  \n",
        "  x = Dense(500, activation='relu')(x)\n",
        "  x = Dense(num_classes, activation='softmax')(x)\n",
        "  \n",
        "  return Model(inp, x, name='LeNet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFUCr-P9c8Ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bayesianLeNet(input_shape, num_classes, enable_dropout=True):\n",
        "  \"\"\"\n",
        "    An example implementation of a Bayesian LeNet convolutional neural network.\n",
        "    \n",
        "    This network uses the Bayesian approximation by Monte Carlo estimations using dropouts.\n",
        "    \n",
        "    To enable Bayesian approxiamtion, set the enable_dropout flag to True.\n",
        "  \"\"\"\n",
        "  \n",
        "  inp = Input(shape=input_shape)\n",
        "  x = Conv2D(filters=20, kernel_size=5, strides=1)(inp)\n",
        "  \n",
        "  x = Dropout(0.5)(x, training=True)\n",
        "  x = MaxPool2D(pool_size=2, strides=2)(x)\n",
        "  x = Conv2D(filters=50, kernel_size=5, strides=1)(x)\n",
        "  \n",
        "  x = Dropout(0.5)(x, training=enable_dropout)\n",
        "  x = MaxPool2D(pool_size=2, strides=2)(x)\n",
        "  x = Flatten()(x)\n",
        "  \n",
        "  x = Dropout(0.5)(x, training=enable_dropout)\n",
        "  x = Dense(500, activation='relu')(x)\n",
        "  \n",
        "  x = Dropout(0.5)(x, training=enable_dropout)\n",
        "  x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "  return Model(inp, x, name='bayesianLeNet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgSEf6cejO6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.datasets import mnist\n",
        "from keras import utils\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A0olNY1jfN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TENSORBOARD_DIR = './tensorboard'\n",
        "MODEL_PATH = './bayesianLeNet.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8pYfmTqjnCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dirs():\n",
        "    if not os.path.isdir(TENSORBOARD_DIR):\n",
        "        os.makedirs(TENSORBOARD_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40by1IKu5s7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_dirs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6GvG2dBjqxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data():\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
        "    X_train = X_train.astype(np.float32) / 255.\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
        "    X_test = X_test.astype(np.float32) / 255.\n",
        "\n",
        "    y_train, y_test = utils.to_categorical(y_train, 10), utils.to_categorical(y_test, 10)\n",
        "\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4co5E0fjx0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ca4c89e9-8b7f-4a9e-c073-ba25f43830c2"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = prepare_data()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxQsVM4IkQbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bayesian_network=True\n",
        "download_weights=True\n",
        "batch_size=1000\n",
        "epochs=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmVpQGyTj0qK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "6b2c5cbb-3cbb-4081-fc16-2433f7ab686a"
      },
      "source": [
        "if bayesian_network:\n",
        "  model = bayesianLeNet(input_shape=X_train.shape[1:],\n",
        "                        num_classes=10)\n",
        "else:\n",
        "  model = LeNet(input_shape=X_train.shape[1:],\n",
        "                num_classes=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArCgOvnF2M4U",
        "colab_type": "text"
      },
      "source": [
        "## Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_491tmClkOu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4uGrJIh2Kmn",
        "colab_type": "text"
      },
      "source": [
        "## Load model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhkkfSsS1S14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e8000f9-5db3-48a5-b78a-2f786f8cee89"
      },
      "source": [
        "if os.path.exists(MODEL_PATH):\n",
        "  model.load_weights(MODEL_PATH)\n",
        "  print ('Loaded model weights from: {}'.format(MODEL_PATH))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model weights from: ./bayesianLeNet.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERdm8svAkd95",
        "colab_type": "text"
      },
      "source": [
        "## Train a Bayesian network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKETEhsIkZy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "2122accc-bdea-4f8b-97c9-77692df6c824"
      },
      "source": [
        "model.fit(x=X_train,\n",
        "          y=y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(X_test, \n",
        "                           y_test),\n",
        "          callbacks=[TensorBoard(log_dir=os.path.join(TENSORBOARD_DIR, \n",
        "                                                      model.name), \n",
        "                                 write_images=True)])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0436 - acc: 0.9865 - val_loss: 0.0495 - val_acc: 0.9861\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0418 - acc: 0.9868 - val_loss: 0.0492 - val_acc: 0.9842\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0420 - acc: 0.9867 - val_loss: 0.0437 - val_acc: 0.9860\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0404 - acc: 0.9872 - val_loss: 0.0417 - val_acc: 0.9862\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0390 - acc: 0.9874 - val_loss: 0.0449 - val_acc: 0.9847\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0398 - acc: 0.9876 - val_loss: 0.0422 - val_acc: 0.9866\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0382 - acc: 0.9874 - val_loss: 0.0468 - val_acc: 0.9857\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0383 - acc: 0.9875 - val_loss: 0.0397 - val_acc: 0.9869\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0384 - acc: 0.9877 - val_loss: 0.0457 - val_acc: 0.9858\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0382 - acc: 0.9876 - val_loss: 0.0427 - val_acc: 0.9865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdfd5489a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5-qQGAclbki",
        "colab_type": "text"
      },
      "source": [
        "## Save model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P76EJTlvlbJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvSdjetIlID5",
        "colab_type": "text"
      },
      "source": [
        "## Build a Bayesian inference function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZpfBaVNjt6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bayesianInference(model, X_test, y_test, eval_steps=10):\n",
        "    batch_size = 1000\n",
        "    \n",
        "    bayesian_error = []\n",
        "\n",
        "    for batch_id in tqdm(range(X_test.shape[0] // batch_size)):\n",
        "        # take batch of data\n",
        "        x = X_test[batch_id * batch_size: (batch_id + 1) * batch_size]\n",
        "        # init empty predictions\n",
        "        y_ = np.zeros((eval_steps, batch_size, y_test[0].shape[0]))\n",
        "\n",
        "        for sample_id in range(eval_steps):\n",
        "            # save predictions from a sample pass\n",
        "            y_[sample_id] = model.predict(x, batch_size)\n",
        "\n",
        "        # average over all passes\n",
        "        mean_y = y_.mean(axis=0)\n",
        "        # evaluate against labels\n",
        "        y = y_test[batch_size * batch_id: (batch_id + 1) * batch_size]\n",
        "        # compute error\n",
        "        point_error = np.count_nonzero(np.not_equal(mean_y.argmax(axis=1), y.argmax(axis=1)))\n",
        "        bayesian_error.append(point_error)\n",
        "\n",
        "    mean_error = np.sum(bayesian_error) / X_test.shape[0]\n",
        "    uncertainty = np.std(bayesian_error) / X_test.shape[0]\n",
        "    mean_accuracy = 1 - mean_error\n",
        "\n",
        "    return [mean_accuracy, uncertainty]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRxd-mXu2E-c",
        "colab_type": "text"
      },
      "source": [
        "## Run Bayesian inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgBg-NBUkqTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f80fe349-e1fd-46b4-f6cd-19ad56f9c994"
      },
      "source": [
        "if bayesian_network:\n",
        "  out = bayesianInference(model, X_test, y_test)\n",
        "  print ('\\n')\n",
        "  print ('\\nValidation accuracy: {} ...'.format(out[0]))\n",
        "  print ('Validation uncertainty: {} ...'.format(out[1]))\n",
        "else:\n",
        "  (_, acc) = model.evaluate(x=X_test,\n",
        "                            y=y_test,\n",
        "                            batch_size=args.batch_size)\n",
        "  print('\\nValidation accuracy: {}'.format(acc))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Validation accuracy: 0.9944 ...\n",
            "Validation uncertainty: 0.00032619012860600184 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN4B04V-4qT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if download_weights:\n",
        "  from google.colab import files\n",
        "  files.download(MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}