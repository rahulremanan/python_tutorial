{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hello World! Python Workshops @ Think Coffee**\n",
    "\n",
    "**3-5pm, 7/30/17**\n",
    "\n",
    "**Day 3, Alice NLP generator**\n",
    "\n",
    "**@python script author (original content): Rahul**\n",
    "\n",
    "**@jupyter notebook converted tutorial author: Nick Giangreco**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ntbk of python script in same directory. Building an RNN based on Lewis Carrol's *Alice in Wonderland* text.**\n",
    "\n",
    "**Importing modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import h5py\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting params for model setup and build.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_path = \"./glove.840B.300d-char.txt\" # http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "embedding_dim = 300\n",
    "batch_size = 32\n",
    "use_pca = False\n",
    "lr = 0.001\n",
    "lr_decay = 1e-4\n",
    "maxlen = 300\n",
    "consume_less = 2   # 0 for cpu, 2 for gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading and reading Alice.txt corpus, saving characters (unique alphabet and punctuation characters in corpus) in array, and making dictionary associating each character with it's position in the character array (making two dictionaries where the key and position are either the key or value)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 148545\n",
      "total chars: 73\n"
     ]
    }
   ],
   "source": [
    "text = open('./Alice.txt').read()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cutting the document into semi-redundant sentences, where each element in the sentences list contain 40 sentences that overlap with the previous element's sentences (also doing a step size of 3 through each line in the text). Also, storing character in each next_chars array's elements, where the current element is the 40th character after the previous character.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 49415\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making X boolean (false) array with a shape of the length of the sentences by the step (40) by the length of the unique characters/punctuation in the document.**\n",
    "\n",
    "**Making y boolean (false) array with a shape of the length of the sentences by the length of the unique characters/punctuation in the document.**\n",
    "\n",
    "**Then, going through each sentence and character in the sentence, storing a 1 (converting false to true) in the respective sentence and characters in X and y.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen), dtype=np.int)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t] = char_indices[char]\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining helper functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test code to sample on 10% for functional model testing\n",
    "\n",
    "def random_subset(X, y, p=0.1):\n",
    "\n",
    "    idx = np.random.randint(X.shape[0], size=int(X.shape[0] * p))\n",
    "    X = X[idx, :]\n",
    "    y = y[idx]\n",
    "    return (X, y)\n",
    "\n",
    "\n",
    "# https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "def generate_embedding_matrix(embeddings_path):\n",
    "    print('Processing pretrained character embeds...')\n",
    "    embedding_vectors = {}\n",
    "    with open(embeddings_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line_split = line.strip().split(\" \")\n",
    "            vec = np.array(line_split[1:], dtype=float)\n",
    "            char = line_split[0]\n",
    "            embedding_vectors[char] = vec\n",
    "\n",
    "    embedding_matrix = np.zeros((len(chars), 300))\n",
    "    #embedding_matrix = np.random.uniform(-1, 1, (len(chars), 300))\n",
    "    for char, i in char_indices.items():\n",
    "        #print (\"{}, {}\".format(char, i))\n",
    "        embedding_vector = embedding_vectors.get(char)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    # Use PCA from sklearn to reduce 300D -> 50D\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=embedding_dim)\n",
    "        pca.fit(embedding_matrix)\n",
    "        embedding_matrix_pca = np.array(pca.transform(embedding_matrix))\n",
    "        embedding_matrix_result = embedding_matrix_pca\n",
    "        print (embedding_matrix_pca)\n",
    "        print (embedding_matrix_pca.shape)\n",
    "    else:\n",
    "        embedding_matrix_result = embedding_matrix\n",
    "    return embedding_matrix_result\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-6) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building text embedding matrix and RNN model. *This is what differentiates this tutorial from tutorial 03*.**\n",
    "\n",
    "* Input layer\n",
    "\n",
    "* Embedding layer - with embedding matrix as weights\n",
    "\n",
    "* RNN Layer - LSTM instance with 256 nodes\n",
    "\n",
    "* Dense layer (2 hidden layers)\n",
    "\n",
    "* Activation (softmax) layer for converting to output probability\n",
    "\n",
    "full table given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Processing pretrained character embeds...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 300, 300)      21900       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 256)           570368      embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 512)           131072      lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 512)           2048        dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 512)           0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 256)           131072      activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 256)           1024        dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 256)           0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 73)            18761       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 73)            18761       lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "main_out (Activation)            (None, 73)            0           dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "aux_out (Activation)             (None, 73)            0           dense_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 895,006\n",
      "Trainable params: 893,470\n",
      "Non-trainable params: 1,536\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "main_input = Input(shape=(maxlen,))\n",
    "embedding_matrix = generate_embedding_matrix(embeddings_path)\n",
    "embedding_layer = Embedding(\n",
    "len(chars), embedding_dim, input_length=maxlen,\n",
    "weights=[embedding_matrix])\n",
    "# embedding_layer = Embedding(\n",
    "#     len(chars), embedding_dim, input_length=maxlen)\n",
    "embedded = embedding_layer(main_input)\n",
    "\n",
    "    # RNN Layer\n",
    "rnn = LSTM(256, implementation=consume_less)(embedded)\n",
    "\n",
    "aux_output = Dense(len(chars))(rnn)\n",
    "aux_output = Activation('softmax', name='aux_out')(aux_output)\n",
    "\n",
    "    # Hidden Layers\n",
    "hidden_1 = Dense(512, use_bias=False)(rnn)\n",
    "hidden_1 = BatchNormalization()(hidden_1)\n",
    "hidden_1 = Activation('relu')(hidden_1)\n",
    "\n",
    "hidden_2 = Dense(256, use_bias=False)(hidden_1)\n",
    "hidden_2 = BatchNormalization()(hidden_2)\n",
    "hidden_2 = Activation('relu')(hidden_2)\n",
    "\n",
    "main_output = Dense(len(chars))(hidden_2)\n",
    "main_output = Activation('softmax', name='main_out')(main_output)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=[main_output, aux_output])\n",
    "\n",
    "optimizer = Adam(lr=lr, decay=lr_decay)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizer, loss_weights=[1., 0.2])\n",
    "model.summary()\n",
    "\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "\n",
    "if not os.path.exists('./output'):\n",
    "    os.makedirs('./output')\n",
    "\n",
    "f = open('./log.csv', 'w')\n",
    "log_writer = csv.writer(f)\n",
    "log_writer.writerow(['iteration', 'batch', 'batch_loss',\n",
    "                     'epoch_loss', 'elapsed_time'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    \"./output/model.hdf5\", monitor='main_out_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making batchloss class for more efficient epoch training and writing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchLossLogger(Callback):\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('main_out_loss'))\n",
    "        if batch % 50 == 0:\n",
    "            log_writer.writerow([iteration, batch,\n",
    "                                 logs.get('main_out_loss'),\n",
    "                                 np.mean(self.losses),\n",
    "                                 round(time.time() - start_time, 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model training. Use one epoch instead of ten.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "49415/49415 [==============================] - 2062s - loss: 2.7572 - main_out_loss: 2.1911 - aux_out_loss: 2.8303  \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e same thing with you,' said the Hatter, and here the\n",
      "conversation dropped, and the party sat silent for a minute,\n",
      "while Alice thought over all she could remember about ravens and\n",
      "writing-desks, which wasn't much.\n",
      "\n",
      "  The Hatter was the first to break the silence.  `What day of\n",
      "the month is it?' he s\"\n",
      "e same thing with you,' said the Hatter, and here the\n",
      "conversation dropped, and the party sat silent for a minute,\n",
      "while Alice thought over all she could remember about ravens and\n",
      "writing-desks, which wasn't much.\n",
      "\n",
      "  The Hatter was the first to break the silence.  `What day of\n",
      "the month is it?' he she saice, and the she she saide the the saice the was she was she was the waid the wis the she was ince the she saide the as ince haid the saide the licked the the came the waid the the saide the she saide the she came the waide the was in the dooke the saide the waid the waid the saide the was she was all the it the the was waide the was ince the she was all caice the saide the the saide the was the came itsee inche the caice the was the came the saide the waid the saide the castell the said the saide the she she came the said the was ince the was the was inge the was of the saide the the saide the the came and the she was waide the she she case the she was ince the saide it the was ince the saide the saide the the waid the she saide the waid the she came the came the was inge the saide the she came the was ince of the waid the she came the the was waid the was ince the waide the waid ittell the the came the was ince all the she waid the came the was ince the saide the wise the she came the she was the saice the she she was the saide the was ince the waid the waid the was inge the saide the the said the the saide the she came the she saide the the said the saide the came the saide\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e same thing with you,' said the Hatter, and here the\n",
      "conversation dropped, and the party sat silent for a minute,\n",
      "while Alice thought over all she could remember about ravens and\n",
      "writing-desks, which wasn't much.\n",
      "\n",
      "  The Hatter was the first to break the silence.  `What day of\n",
      "the month is it?' he s\"\n",
      "e same thing with you,' said the Hatter, and here the\n",
      "conversation dropped, and the party sat silent for a minute,\n",
      "while Alice thought over all she could remember about ravens and\n",
      "writing-desks, which wasn't much.\n",
      "\n",
      "  The Hatter was the first to break the silence.  `What day of\n",
      "the month is it?' he she Rase waided, it heas whid the faice intte waide the\n",
      "saided.  `You she she meell the all of heak\n",
      "\n",
      "  `I was waike the all to becke the said the wise all ass veese caice The paicke the bease the licke in off uell itteed the shating one the beeare waise the camet it the METTE TEETE TOTTEE TOATETOETENTEES Lall gusise thee the the or was daide the dookeng one waiding the it haid the was of ink waise the waid the silk the came them wasing `I wall ittle said the inow the saide of in the what waide the waid the saide all the saice the wis witeld the fhicke the keailse, and is waid the call istell them bese she she thise it the puches waild thing weas is the Greme of bee of as the licked the was ill was as the wis inseee, `I wis was was istle the whied incesid.  `I wit heaking, and time ill ittell the the she sell outen all the it ink the wise aboce ance the said.'\n",
      "\n",
      "  `You deaid the dooke and heam Alice und, and the the saide itsle the saided wis istlick in the heat wall of, and waice the waide the she paice inow the was Alice us waid the was the sicke saide the and, and she she was waid and the she saice.  `You waid--\n",
      "                                                                      \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e same thing with you,' said the Hatter, and here the\n",
      "conversation dropped, and the party sat silent for a minute,\n",
      "while Alice thought over all she could remember about ravens and\n",
      "writing-desks, which wasn't much.\n",
      "\n",
      "  The Hatter was the first to break the silence.  `What day of\n",
      "the month is it?' he s\"\n",
      "e same thing with you,' said the Hatter, and here the\n",
      "conversation dropped, and the party sat silent for a minute,\n",
      "while Alice thought over all she could remember about ravens and\n",
      "writing-desks, which wasn't much.\n",
      "\n",
      "  The Hatter was the first to break the silence.  `What day of\n",
      "the month is it?' he saokige.\n",
      "\n",
      " `Bustle Labk-ino ing neiw-j:\n",
      "  IN, rame onk Ratteir the veotesers, `it Cal came puchh, whe saiig lell et'me teir KIEN Ale Alice womed.'\n",
      "\n",
      "  The, shevumely.'\n",
      "\n",
      "   `You Mly she gustlige `Allege Alece heak\n",
      "theen ther, `paway\n",
      "grilltgry\n",
      "uo.-\n",
      "\n",
      "  `-\n",
      "                      Thimee-saisey\n",
      "is the in allockete istlee, as she doret ing, andwez's the\n",
      "sOREE TITT TTiee. \n",
      "  `'nd'l didiokedy aicee:  `Yed bkeme.\n",
      "\n",
      "  `Dusle\n",
      "Ill Coce tive's DaAl \n",
      "                   the un!  Raide them abike thig, it Alice yougselng.\n",
      "\n",
      "  The her.  Tnokese thes nime theahs oneking ittle of comee daidenou--\"Ands awo 'sjeonged at ine istelf.'\n",
      "\n",
      "  `You?   littlen?  Here them UTESETKiu--hat hat breves bep?' \n",
      "  `YUch daid.\n",
      "\n",
      "\n",
      "  ` snouking hand quet, \n",
      "`Yey' laiging the salle soo?'\n",
      "\n",
      "                  Th Boee nmel once dookeng,  I bis whi may theme conken's and, (is neppe ilseoted it allsngey'y\n",
      "leawene,' rendied Ill efpy iddy urcave to , herdy's ROINTRE's Rref theme thaide them Bucend ifmieed Alice, `Oum bame, it the ind.  `Nuok daide thaily aid; `noug Alice on, Quet I'm--tre I Al waid the  apgilly Aliceing peio ' laidong of, was'\n",
      "\n",
      "  She whatteger!' said theid---'\n",
      "\n",
      "  `Yhe worde, pIT I\n",
      "NElD allrucelfnlow the camn_ as ne! he is\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e same thing with you,' said the Hatter, and here the\n",
      "conversation dropped, and the party sat silent for a minute,\n",
      "while Alice thought over all she could remember about ravens and\n",
      "writing-desks, which wasn't much.\n",
      "\n",
      "  The Hatter was the first to break the silence.  `What day of\n",
      "the month is it?' he s\"\n",
      "e same thing with you,' said the Hatter, and here the\n",
      "conversation dropped, and the party sat silent for a minute,\n",
      "while Alice thought over all she could remember about ravens and\n",
      "writing-desks, which wasn't much.\n",
      "\n",
      "  The Hatter was the first to break the silence.  `What day of\n",
      "the month is it?' he siose buce HEYNTTET DOYT OUEV LORDHELWE CLU O heas you on osm,\n",
      "yelf Maje\n",
      "MAAS Tooke---Heny\n",
      "agybut it! illle.\n",
      "\n",
      "  I'mb\n",
      "\"aeLodsay. fuy gas it; yucking,  I le, Fuy (Bucch) ta\n",
      "keast-uninga\":  see thald' iot'bong iefiou AlSILTE MEULbiS (Yais,' said to laiseas, `indmenme--`YOTT SARLO TAINl-MO fubet: theoke, whe kise it\n",
      "bs ligessong?'\n",
      "\n",
      "  ``Howc RhALE ag--is\n",
      "ixwa giwatioo?'\n",
      "\n",
      "  I'vid.\n",
      "  `Nelvce,  andyeh:  puncse's it)a wLAHTHGE\n",
      "iapusingednuged thelilf vee in toe haid it'll--inomeor. (Aliee of lattwe) olkez'ss; buitskam--a\n",
      "(wand All !' Asie fuel onckliok--`IN snawnle otplbaice notle bepetncoomedsH\n",
      "teck Oas-Se sheb--WOOET\n",
      "sMat naw in-zAmE quie Tuicc mem--co maice, saidiy--o\n",
      "draotes?'\n",
      "\n",
      " `Bow the!\n",
      "\"no pavbieeds,' she as nasem-'\"'\n",
      "\n",
      "\n",
      " Ticke Alice: Shy whir\n",
      "cawiall bce jum, FO ATEATTEIRH TORT han'tpsiokeded, cim deatted JeRAUTATTE\n",
      "TORE TOR OTADENE\n",
      "       `YES -O EeEVTK joineet, `Sou MOSEB\" urie-sowe. yOw ixteem.  Lheurver--aele ceall nece, and ther nele ter, and as.) `I MON AE CHTER LNEF VETTOPTEI DOLNKTTEEL INE AT\n",
      "kEEAOTEESEYL ILA RNSENTEHTTENTET eAs\n",
      "OOALUSS YWI RBE  Shik-bid; thee vacg up tmear.'\n",
      "\n",
      " Shaice briknuttundiot\n",
      "Foquee.  `\n",
      "Yhis.  Whem Tnougedd Thike.'\n",
      "\n",
      "  `Yuy'm--\n",
      "\n",
      "              bodye dhikl\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "  704/49415 [..............................] - ETA: 2096s - loss: 2.5736 - main_out_loss: 2.0791 - aux_out_loss: 2.4725"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6634de9a3d9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#                     epochs=1, callbacks=[logger, checkpointer])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     history = model.fit(X, [y, y], batch_size=batch_size,\n\u001b[0;32m---> 12\u001b[0;31m                         epochs=ep, callbacks=[logger, checkpointer])\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'main_out_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for iteration in range(1, 20):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "\n",
    "    logger = BatchLossLogger()\n",
    "    # X_train, y_train = random_subset(X, y)\n",
    "    # history = model.fit(X_train, [y_train, y_train], batch_size=batch_size,\n",
    "    #                     epochs=1, callbacks=[logger, checkpointer])\n",
    "    history = model.fit(X, [y, y], batch_size=batch_size,\n",
    "                        epochs=ep, callbacks=[logger, checkpointer])\n",
    "    loss = str(history.history['main_out_loss'][-1]).replace(\".\", \"_\")\n",
    "\n",
    "    f2 = open('./output/iter-{:02}-{:.6}.txt'.format(iteration, loss), 'w')\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        f2.write('----- diversity:' + ' ' + str(diversity) + '\\n')\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        f2.write('----- Generating with seed: \"' + sentence + '\"' + '\\n---\\n')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(1200):\n",
    "            x = np.zeros((1, maxlen), dtype=np.int)\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t] = char_indices[char]\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0][0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        f2.write(generated + '\\n')\n",
    "        print()\n",
    "    f2.close()\n",
    "\n",
    "    # Write embeddings for current characters to file\n",
    "    # The second layer has the embeddings.\n",
    "\n",
    "    embedding_weights = model.layers[1].get_weights()[0]\n",
    "    f3 = open('./output/char-embeddings.txt', 'w')\n",
    "    for char in char_indices:\n",
    "        if ord(char) < 128:\n",
    "            embed_vector = embedding_weights[char_indices[char], :]\n",
    "            f3.write(char + \" \" + \" \".join(str(x)\n",
    "                                           for x in embed_vector) + \"\\n\")\n",
    "    f3.close()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Increasing diversity in the model decreases the model predictions (output text).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
