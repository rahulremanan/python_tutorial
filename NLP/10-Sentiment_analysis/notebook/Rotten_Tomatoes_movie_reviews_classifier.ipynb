{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Rotten-Tomatoes_movie_reviews_classifier_jesseedits.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEyH-OGNp-oF",
        "colab_type": "text"
      },
      "source": [
        "# Rotten Tomatoes movie review classifier using Keras and Tensorflow\n",
        "\n",
        "## Author: \n",
        "### [Dr. Rahul Remanan](https://www.linkedin.com/in/rahulremanan) {rahul@moad.computer}\n",
        "### [Dr. Jesse Kanter](https://www.linkedin.com/in/jessekanter) {jessekanter@gmail.com}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   [Kaggle Rotten Tomatoes datasets](https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only/data)\n",
        "* [This is a modified fork of the Kaggle kernel here](https://www.kaggle.com/nafisur/keras-models-lstm-cnn-gru-bidirectional-glove)\n",
        "\n",
        "\n",
        "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
        "\n",
        "## [Open this notebook in Google CoLab](https://colab.research.google.com/github/rahulremanan/python_tutorial/blob/master/NLP/10-Sentiment_analysis/notebook/Rotten_Tomatoes_movie_reviews_classifier.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNBXSE9fsHHX",
        "colab_type": "text"
      },
      "source": [
        "## Upload Kaggle authentication token\n",
        "\n",
        "Before downloading the data, ensure that the [terms of the competition](https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only/rules) is accepted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pneXAB2MEJ8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pKJHr6Pp27f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab_mode = True\n",
        "download_rawData = True\n",
        "setup = True\n",
        "\n",
        "ROOT_DIR = '/content/'\n",
        "WEIGHTS_FILENAME = 'RT_LSTM.h5'\n",
        "WEIGHTS_FILE = os.path.join(ROOT_DIR, WEIGHTS_FILENAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXdc1Igdr0EG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAF-6nCsrpbu",
        "colab_type": "code",
        "outputId": "e97f9be1-bc08-4004-e011-7221e7b0bd13",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "if colab_mode and download_rawData:\n",
        "  files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d61d9f30-146c-4045-ae05-52775258ef1e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d61d9f30-146c-4045-ae05-52775258ef1e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l3D0SasuCEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if colab_mode and download_rawData:\n",
        "  ! mkdir /root/.kaggle/\n",
        "  ! mv /content/kaggle.json /root/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E712QDqys-fv",
        "colab_type": "code",
        "outputId": "23f4d871-e73e-4e73-dbfc-a76b4b3750cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "if setup:\n",
        "  ! pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBJFWWGltrgI",
        "colab_type": "text"
      },
      "source": [
        "## Download the Rotten Tomatoes movie reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T71LYV58tfwh",
        "colab_type": "code",
        "outputId": "fa713871-8922-4173-b63c-ec478c2a4fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "! kaggle competitions download -c movie-review-sentiment-analysis-kernels-only"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading test.tsv.zip to /content\n",
            "  0% 0.00/494k [00:00<?, ?B/s]\n",
            "100% 494k/494k [00:00<00:00, 67.6MB/s]\n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/583k [00:00<?, ?B/s]\n",
            "100% 583k/583k [00:00<00:00, 78.9MB/s]\n",
            "Downloading train.tsv.zip to /content\n",
            "  0% 0.00/1.28M [00:00<?, ?B/s]\n",
            "100% 1.28M/1.28M [00:00<00:00, 86.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKgkuvnYDzQi",
        "colab_type": "code",
        "outputId": "6d2b5b5b-2cbb-47a1-f2a3-6b1b9b9f7759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "! kaggle datasets download -d terenceliu4444/glove6b100dtxt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading glove6b100dtxt.zip to /content\n",
            " 99% 130M/131M [00:02<00:00, 46.0MB/s]\n",
            "100% 131M/131M [00:02<00:00, 57.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t0de0Cjt96Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "196G7hKXvVTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if setup:\n",
        "  ! unzip -q /content/train.tsv.zip\n",
        "  ! unzip -q /content/test.tsv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk7bW5lsEYYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if setup:\n",
        "  ! unzip -q /content/glove6b100dtxt.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOu7FtoJv2tc",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVpQb8-Svdv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#pd.set_option('display.max_colwidth',100)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ktgv8DO5wbXz",
        "colab_type": "text"
      },
      "source": [
        "## Read the train data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4JkLbd_wKru",
        "colab_type": "code",
        "outputId": "0973a6f6-157f-4114-9af9-31b279f60528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "train=pd.read_csv('/content/train.tsv',sep='\\t')\n",
        "print(train.shape)\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(156060, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0  1         ...  1        \n",
              "1  2         ...  2        \n",
              "2  3         ...  2        \n",
              "3  4         ...  2        \n",
              "4  5         ...  2        \n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygasEVElw01B",
        "colab_type": "text"
      },
      "source": [
        "## Summarize the training data\n",
        "\n",
        "### Get the [unqiue label values](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html) in the training data\n",
        "\n",
        "The sentiment labels are:\n",
        "\n",
        "* 0 - negative\n",
        "* 1 - somewhat negative\n",
        "* 2 - neutral\n",
        "* 3 - somewhat positive\n",
        "* 4 - positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMWejboZwWy3",
        "colab_type": "code",
        "outputId": "c393db0e-d76d-420b-fd87-edd670914e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train['Sentiment'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1KMph0slMzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " Sent_dic={0:'negative', 1:'somewhat negative', 2:'neutral', 3:'somewhat positive', 4:'positive'}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b14UVw0yQdH",
        "colab_type": "text"
      },
      "source": [
        "### Count the total number of training items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHdZQeJpwo32",
        "colab_type": "code",
        "outputId": "25dcfde3-a06a-4b87-d3bd-f14df1a722cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train['Sentiment'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156060"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAew6xJIyVRc",
        "colab_type": "text"
      },
      "source": [
        "### Summarize the distribution of the sentiment classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9QWrJJuxZkm",
        "colab_type": "code",
        "outputId": "0fcfecc5-e602-4033-9b66-5955ca0342ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train.groupby('Sentiment')['PhraseId'].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "0    7072 \n",
              "1    27273\n",
              "2    79582\n",
              "3    32927\n",
              "4    9206 \n",
              "Name: PhraseId, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TWMmjkYS7Pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNEchrGwTAGZ",
        "colab_type": "code",
        "outputId": "69ef5e30-cb83-4f70-80dc-092c1b1d91f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "sns.countplot(data=train,x='Sentiment',)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f672d2651d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1maWswBykmY",
        "colab_type": "text"
      },
      "source": [
        "## Load test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB-7NR9Gx7Nq",
        "colab_type": "code",
        "outputId": "99d7f612-5f9f-46ee-abdd-741df690cfbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "test=pd.read_csv('/content/test.tsv',sep='\\t')\n",
        "print(test.shape)\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66292, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine effort .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  SentenceId                                                  Phrase\n",
              "0  156061    8545        An intermittently pleasing but mostly routine effort .\n",
              "1  156062    8545        An intermittently pleasing but mostly routine effort  \n",
              "2  156063    8545        An                                                    \n",
              "3  156064    8545        intermittently pleasing but mostly routine effort     \n",
              "4  156065    8545        intermittently pleasing but mostly routine            "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5BHmyNoyt72",
        "colab_type": "text"
      },
      "source": [
        "## Load the sample submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX2ZSfweyo7q",
        "colab_type": "code",
        "outputId": "a3c0c6a6-a5d2-48f7-a931-6aba244dd7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sub=pd.read_csv('/content/sampleSubmission.csv')\n",
        "sub.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  Sentiment\n",
              "0  156061    2        \n",
              "1  156062    2        \n",
              "2  156063    2        \n",
              "3  156064    2        \n",
              "4  156065    2        "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtNWrsCrzEbF",
        "colab_type": "text"
      },
      "source": [
        "## Create sentiment column in the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtlPJB6Myw3X",
        "colab_type": "code",
        "outputId": "2b138086-4049-4109-8ffe-a8f1152ef015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test['Sentiment']=-999\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine effort .</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine effort</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0  156061    ... -999      \n",
              "1  156062    ... -999      \n",
              "2  156063    ... -999      \n",
              "3  156064    ... -999      \n",
              "4  156065    ... -999      \n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3Fi6uC4zkDE",
        "colab_type": "text"
      },
      "source": [
        "## Create a dataframe to store both train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wby5eJlSzL_x",
        "colab_type": "code",
        "outputId": "bd895282-8c4c-4d4c-8b9f-68f458b533fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df=pd.concat([train,\n",
        "              test], ignore_index=True)\n",
        "print(df.shape)\n",
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(222352, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>222347</th>\n",
              "      <td>222348</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded , predictable scenario .</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222348</th>\n",
              "      <td>222349</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded , predictable scenario</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222349</th>\n",
              "      <td>222350</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded ,</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222350</th>\n",
              "      <td>222351</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222351</th>\n",
              "      <td>222352</td>\n",
              "      <td>11855</td>\n",
              "      <td>predictable scenario</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PhraseId  SentenceId                                  Phrase  Sentiment\n",
              "222347  222348    11855       A long-winded , predictable scenario . -999      \n",
              "222348  222349    11855       A long-winded , predictable scenario   -999      \n",
              "222349  222350    11855       A long-winded ,                        -999      \n",
              "222350  222351    11855       A long-winded                          -999      \n",
              "222351  222352    11855       predictable scenario                   -999      "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA8wQheazd9A",
        "colab_type": "code",
        "outputId": "1e90f0d9-d427-4205-e8da-903d0abec252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "del train,test\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "282"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrj087uJeQQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSwhDgKUzwJE",
        "colab_type": "text"
      },
      "source": [
        "## Pre-process the movie review string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7U6s6EIzie0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
        "stemmer=SnowballStemmer('english')\n",
        "lemma=WordNetLemmatizer()\n",
        "from string import punctuation\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UADSGnoa0ilr",
        "colab_type": "text"
      },
      "source": [
        "### Download NLTK datasets\n",
        "\n",
        "Specify the NLTK corpus as 'punkt' or 'all'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu_idt0-0iMq",
        "colab_type": "code",
        "outputId": "07b80671-669b-48f3-d73b-6e9288caf216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3774
        }
      },
      "source": [
        "if setup:\n",
        "  nltk.download()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all\n",
            "    Downloading collection 'all'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Unzipping corpora/alpino.zip.\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Unzipping corpora/biocreative_ppi.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown.zip.\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown_tei.zip.\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_cat.zip.\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_esp.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/comparative_sentences.zip.\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Unzipping corpora/crubadan.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Unzipping corpora/dolch.zip.\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Unzipping corpora/europarl_raw.zip.\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Unzipping corpora/floresta.zip.\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v15.zip.\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v17.zip.\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Unzipping corpora/indian.zip.\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Unzipping corpora/kimmo.zip.\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Unzipping corpora/lin_thesaurus.zip.\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Unzipping corpora/mac_morpho.zip.\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Unzipping models/moses_sample.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       |   Unzipping corpora/omw.zip.\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Unzipping corpora/opinion_lexicon.zip.\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Unzipping corpora/paradigms.zip.\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Unzipping corpora/pil.zip.\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Unzipping corpora/pl196x.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Unzipping corpora/problem_reports.zip.\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Unzipping corpora/ptb.zip.\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_1.zip.\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_2.zip.\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Unzipping corpora/pros_cons.zip.\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Unzipping corpora/qc.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Unzipping corpora/rte.zip.\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentiwordnet.zip.\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentence_polarity.zip.\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/sinica_treebank.zip.\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Unzipping corpora/smultron.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Unzipping corpora/subjectivity.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Unzipping corpora/switchboard.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet.zip.\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet3.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet.zip.\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Unzipping corpora/ycoe.zip.\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Unzipping stemmers/rslp.zip.\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Unzipping taggers/universal_tagset.zip.\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/sample_grammars.zip.\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/spanish_grammars.zip.\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/basque_grammars.zip.\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/large_grammars.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Unzipping models/word2vec_sample.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Unzipping corpora/mte_teip5.zip.\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Unzipping misc/perluniprops.zip.\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Unzipping stemmers/porter_test.zip.\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Unzipping models/wmt15_eval.zip.\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Unzipping misc/mwa_ppdb.zip.\n",
            "       | \n",
            "     Done downloading collection all\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqdpNyzwz2sE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_review(review_col):\n",
        "    review_corpus=[]\n",
        "    for i in range(0,len(review_col)):\n",
        "        review=str(review_col[i])\n",
        "        review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        #review=[stemmer.stem(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=' '.join(review)\n",
        "        review_corpus.append(review)\n",
        "    return review_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3J3Fsywz4DB",
        "colab_type": "code",
        "outputId": "036536a7-9064-4356-f8c3-615245fbcbc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df['clean_review']=clean_review(df.Phrase.values)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>series</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...                                                                                                                                                                            clean_review\n",
              "0  1         ...  a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story\n",
              "1  2         ...  a series of escapade demonstrating the adage that what is good for the goose                                                                                                          \n",
              "2  3         ...  a series                                                                                                                                                                              \n",
              "3  4         ...  a                                                                                                                                                                                     \n",
              "4  5         ...  series                                                                                                                                                                                \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLQa4G0L0WfQ",
        "colab_type": "code",
        "outputId": "e1651901-a5bf-43e5-f49b-3a375bcd24e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "df_train=df[df.Sentiment!=-999]\n",
        "print (df_train.shape)\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(156060, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>series</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...                                                                                                                                                                            clean_review\n",
              "0  1         ...  a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story\n",
              "1  2         ...  a series of escapade demonstrating the adage that what is good for the goose                                                                                                          \n",
              "2  3         ...  a series                                                                                                                                                                              \n",
              "3  4         ...  a                                                                                                                                                                                     \n",
              "4  5         ...  series                                                                                                                                                                                \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO-kNuAG1_5u",
        "colab_type": "code",
        "outputId": "dfb2e24e-7e37-4cb9-f4b1-3a135222fded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df_test=df[df.Sentiment==-999]\n",
        "df_test.drop('Sentiment',axis=1,inplace=True)\n",
        "print(df_test.shape)\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66292, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>156060</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine effort .</td>\n",
              "      <td>an intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156061</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine effort</td>\n",
              "      <td>an intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156062</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "      <td>an</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156063</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156064</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PhraseId  ...                                          clean_review\n",
              "156060  156061    ...  an intermittently pleasing but mostly routine effort\n",
              "156061  156062    ...  an intermittently pleasing but mostly routine effort\n",
              "156062  156063    ...  an                                                  \n",
              "156063  156064    ...  intermittently pleasing but mostly routine effort   \n",
              "156064  156065    ...  intermittently pleasing but mostly routine          \n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSlXk0HE2Et5",
        "colab_type": "code",
        "outputId": "e01f5bef-90c7-49fd-a811-66d70805891d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "del df\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOLWegg42V6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text=df_train.clean_review.values\n",
        "test_text=df_test.clean_review.values\n",
        "target=df_train.Sentiment.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XYXqUlLqoNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7WuJq502hMP",
        "colab_type": "text"
      },
      "source": [
        "## Convert labels to categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgFS2l4j2fou",
        "colab_type": "code",
        "outputId": "bb4ff9c2-41a5-4d25-ab90-d0fcccb7e491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y=to_categorical(target)\n",
        "print(train_text.shape,target.shape,y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(156060,) (156060,) (156060, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z3-sAGM3B98",
        "colab_type": "text"
      },
      "source": [
        "## Create train-validation split for training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcYgunI-2ofp",
        "colab_type": "code",
        "outputId": "749a8573-a9c7-4042-aea5-03bef73dada5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train_text,X_val_text,y_train,y_val=train_test_split(train_text,y,test_size=0.2,stratify=y,random_state=123)\n",
        "print(X_train_text.shape,y_train.shape)\n",
        "print(X_val_text.shape,y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124848,) (124848, 5)\n",
            "(31212,) (31212, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2U8knkq3AwT",
        "colab_type": "code",
        "outputId": "aeaaaad7-9251-48bf-aeb5-2fb02c255066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_words=' '.join(X_train_text)\n",
        "all_words=word_tokenize(all_words)\n",
        "dist=FreqDist(all_words)\n",
        "num_unique_word=len(dist)\n",
        "num_unique_word"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13732"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vQuzXFa3aar",
        "colab_type": "text"
      },
      "source": [
        "## Finding the maximum length of the review in the training corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrKkega23LwM",
        "colab_type": "code",
        "outputId": "0b92fe40-76ce-4047-dca2-c1a7a805adac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r_len=[]\n",
        "for text in X_train_text:\n",
        "    word=word_tokenize(text)\n",
        "    l=len(word)\n",
        "    r_len.append(l)\n",
        "    \n",
        "MAX_REVIEW_LEN=np.max(r_len)\n",
        "MAX_REVIEW_LEN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmFhMRcw3gB1",
        "colab_type": "code",
        "outputId": "48aba859-8698-43a3-fe66-d3c56b998588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_features = num_unique_word\n",
        "max_words = MAX_REVIEW_LEN\n",
        "batch_size = 128\n",
        "epochs = 3\n",
        "num_classes=y.shape[1]\n",
        "print ('Total number of sentiment classes: {} ...'.format(num_classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of sentiment classes: 5 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX0rspAA4FkD",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize the input text\n",
        "\n",
        "Tokenizing using [Keras text pre-processor](https://keras.io/preprocessing/text/). This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNpXDm2q3_PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train_text))\n",
        "X_train = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_val = tokenizer.texts_to_sequences(X_val_text)\n",
        "X_test = tokenizer.texts_to_sequences(test_text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcy6-c0R5Vx1",
        "colab_type": "text"
      },
      "source": [
        "## Padding the input text for a fixed input length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-tkw_SW5RYJ",
        "colab_type": "code",
        "outputId": "d84b4c3a-1c8b-4902-808b-772331cd8865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "print(X_train.shape,X_val.shape,X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124848, 48) (31212, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cp_Xxxe7eGW",
        "colab_type": "text"
      },
      "source": [
        "## The role of [embedding layer in a neural network](https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.  One-hot encoded vectors are high-dimensional and sparse. Lets assume that we are doing Natural Language Processing (NLP) and have a dictionary of 2000 words. This means that, when using one-hot encoding, each word will be represented by a vector containing 2000 integers. And 1999 of these integers are zeros. In a big dataset this approach is not computationally efficient.\n",
        "\n",
        "2.   The vectors of each embedding get updated while training the neural network. If you have seen the image at the top of this post you can see how similarities between words can be found in a multi-dimensional space. This allows us to visualize relationships between words, but also between everything that can be turned into a vector through an embedding layer.\n",
        "\n",
        "[Read more about keras embedding layer](https://keras.io/layers/embeddings/#embedding)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG1s_IaX9taM",
        "colab_type": "text"
      },
      "source": [
        "###LSTM Model\n",
        "## Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_A_4VFB5auL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_LSTM():\n",
        "  model=Sequential()\n",
        "  model.add(Embedding(max_features,100,mask_zero=True))\n",
        "  model.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
        "  model.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "  model.add(Dense(4096, activation='tanh'))\n",
        "  model.add(Dense(num_classes,activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtXJy0YEMj_x",
        "colab_type": "text"
      },
      "source": [
        "## Build and compile the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7S6WvsR8JBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = model_LSTM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFu_COGh8Bbb",
        "colab_type": "code",
        "outputId": "6fb2af19-acc0-40ed-f1de-283c2b63e065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001),\n",
        "              metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 100)         1373200   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, None, 64)          42240     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              135168    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 20485     \n",
            "=================================================================\n",
            "Total params: 1,583,509\n",
            "Trainable params: 1,583,509\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq7FFkmRMRN7",
        "colab_type": "text"
      },
      "source": [
        "## Fetch saved model weights and load the weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmXQ44LuMQxh",
        "colab_type": "code",
        "outputId": "512c1723-8a1e-4fba-f6df-b3ce3a6c28a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "! wget https://github.com/rahulremanan/python_tutorial/raw/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
        "  \n",
        "try:\n",
        "  model1.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-20 14:30:54--  https://github.com/rahulremanan/python_tutorial/raw/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5 [following]\n",
            "--2019-05-20 14:30:54--  https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5673112 (5.4M) [application/octet-stream]\n",
            "Saving to: RT_LSTM.h5.1\n",
            "\n",
            "RT_LSTM.h5.1        100%[===================>]   5.41M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-20 14:30:55 (48.2 MB/s) - RT_LSTM.h5.1 saved [5673112/5673112]\n",
            "\n",
            "Loaded model weights from: /content/RT_LSTM.h5 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTkB2n2IMg8F",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeMWqxAy8Nxj",
        "colab_type": "code",
        "outputId": "7634601f-66db-45da-cb86-e4ec90b6b2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%%time\n",
        "history1=model1.fit(X_train, \n",
        "                    y_train, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=epochs, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 124848 samples, validate on 31212 samples\n",
            "Epoch 1/3\n",
            "124848/124848 [==============================] - 311s 2ms/step - loss: 0.7579 - acc: 0.6867 - val_loss: 0.8110 - val_acc: 0.6676\n",
            "Epoch 2/3\n",
            "124848/124848 [==============================] - 308s 2ms/step - loss: 0.7272 - acc: 0.6991 - val_loss: 0.8126 - val_acc: 0.6699\n",
            "Epoch 3/3\n",
            "124848/124848 [==============================] - 307s 2ms/step - loss: 0.7009 - acc: 0.7069 - val_loss: 0.8082 - val_acc: 0.6714\n",
            "CPU times: user 21min 53s, sys: 1min 53s, total: 23min 46s\n",
            "Wall time: 15min 29s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX0QIIVUDkGI",
        "colab_type": "text"
      },
      "source": [
        "## Save the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nym5ngCrAtMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.save_weights(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvVQyYSmG3Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQwYht-MDnKq",
        "colab_type": "text"
      },
      "source": [
        "## Load model weights from weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXBNURGaA2Cy",
        "colab_type": "code",
        "outputId": "876f813f-1354-44c4-fe79-1a4c8342225a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  model1.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model weights from: /content/RT_LSTM.h5 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok0vEvqBl8Gf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuQWOVRa-ZQY",
        "colab_type": "text"
      },
      "source": [
        "## Running model inference on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOGAqbqW-Hi9",
        "colab_type": "code",
        "outputId": "bd90c07c-17be-43cb-9859-0f9500eac287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_element=5\n",
        "input_sequence = np.asarray([list(X_test[test_element])])\n",
        "y_pred_LSTM=model1.predict(input_sequence,verbose=1)\n",
        "print ('Input string: {} ...'.format(test_text[test_element]))\n",
        "print ('Sentiment for the input string: {} ...'.format(Sent_dic[np.argmax(y_pred_LSTM)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 1s 756ms/step\n",
            "Input string: intermittently pleasing but ...\n",
            "Sentiment for the input string: neutral ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_jZ6Bih9Wf_",
        "colab_type": "code",
        "outputId": "71418ee9-01e3-4bf1-9bb4-1f9265bd165b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(y_pred_LSTM)\n",
        "Sent_dic[np.argmax(y_pred_LSTM)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00064461 0.01940043 0.6235409  0.33569595 0.02071818]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neutral'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0nmqq6kDRTF",
        "colab_type": "text"
      },
      "source": [
        "## Run inference for custom user input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doT362JZCE3S",
        "colab_type": "code",
        "outputId": "c856899b-dbf7-4f36-cc48-3ad16493b424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "input_string = ['This movie was horrible']\n",
        "input_text = tokenizer.texts_to_sequences(input_string)\n",
        "input_sequence = sequence.pad_sequences(input_text, maxlen=max_words)\n",
        "y_pred_LSTM=model1.predict(input_sequence,verbose=1)\n",
        "print ('Input string: {} ...'.format(input_string))\n",
        "print ('Sentiment for the input string: {} ...'.format(Sent_dic[np.argmax(y_pred_LSTM)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 78ms/step\n",
            "Input string: ['This movie was horrible'] ...\n",
            "Sentiment for the input string: negative ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmVFhqB3AF0u",
        "colab_type": "code",
        "outputId": "376e98e7-698c-49f5-8fb1-799de925ab4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "input_string = ['this movie was great']\n",
        "input_text = tokenizer.texts_to_sequences(input_string)\n",
        "input_sequence = sequence.pad_sequences(input_text, maxlen=max_words)\n",
        "y_pred_LSTM=model1.predict(input_sequence,verbose=1)\n",
        "print ('Input string: {} ...'.format(input_string))\n",
        "print ('Sentiment for the input string: {} ...'.format(Sent_dic[np.argmax(y_pred_LSTM)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 79ms/step\n",
            "Input string: ['this movie was great'] ...\n",
            "Sentiment for the input string: somewhat positive ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFPjm-eU8HAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y5RGUSD4lfz8"
      },
      "source": [
        "###CNN Model\n",
        "## Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N-KzKpu-lfz9",
        "colab": {}
      },
      "source": [
        "def model_CNN():\n",
        "  model= Sequential()\n",
        "  model.add(Embedding(max_features,100,input_length=max_words))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv1D(64,kernel_size=3,padding='same',activation='relu',strides=1))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dense(128,activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(num_classes,activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mHULdvlelfz_"
      },
      "source": [
        "## Build and compile the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7p7pEOihlf0A",
        "colab": {}
      },
      "source": [
        "model2 = model_CNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "59631cde-3d43-4c10-9269-d9cea45c08f7",
        "id": "mgTD8hpIlf0D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 48, 100)           1373200   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 48, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 48, 64)            19264     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 1,401,429\n",
            "Trainable params: 1,401,429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TCVW3Niklf0G"
      },
      "source": [
        "## Fetch saved model weights and load the weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9c05a2a8-6b99-47b0-fda3-09b3e62f252d",
        "id": "hOre3db4lf0H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "#! wget https://github.com/rahulremanan/python_tutorial/raw/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
        "  \n",
        "try:\n",
        "  model2.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-20 13:28:12--  https://github.com/rahulremanan/python_tutorial/raw/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5 [following]\n",
            "--2019-05-20 13:28:12--  https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5673112 (5.4M) [application/octet-stream]\n",
            "Saving to: RT_LSTM.h5\n",
            "\n",
            "RT_LSTM.h5          100%[===================>]   5.41M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-20 13:28:13 (45.9 MB/s) - RT_LSTM.h5 saved [5673112/5673112]\n",
            "\n",
            "No model weights file: /content/RT_LSTM.h5 found ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zBupvhgwlf0M"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f361a7c4-21d7-4754-cc9c-448263b5344a",
        "id": "jI3R6-Lilf0N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%%time\n",
        "history2=model2.fit(X_train, \n",
        "                    y_train, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=epochs, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 124848 samples, validate on 31212 samples\n",
            "Epoch 1/3\n",
            "124848/124848 [==============================] - 11s 86us/step - loss: 0.6453 - acc: 0.7299 - val_loss: 0.8099 - val_acc: 0.6698\n",
            "Epoch 2/3\n",
            "124848/124848 [==============================] - 11s 86us/step - loss: 0.6030 - acc: 0.7448 - val_loss: 0.8322 - val_acc: 0.6672\n",
            "Epoch 3/3\n",
            "124848/124848 [==============================] - 11s 90us/step - loss: 0.5682 - acc: 0.7593 - val_loss: 0.8665 - val_acc: 0.6547\n",
            "CPU times: user 33.6 s, sys: 6.15 s, total: 39.7 s\n",
            "Wall time: 32.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gzXQuJSolf0P"
      },
      "source": [
        "## Save the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-VNSSrN-lf0R",
        "colab": {}
      },
      "source": [
        "model2.save_weights(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DivHWtghlf0T",
        "colab": {}
      },
      "source": [
        "files.download(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NmmE7Zoqlf0V"
      },
      "source": [
        "## Load model weights from weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ff6c7aeb-13c7-4505-a4ad-0865ba6c2454",
        "id": "W6QehoCvlf0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  model2.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model weights from: /content/RT_LSTM.h5 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YL68Dmb_lf0Z"
      },
      "source": [
        "## Running model inference on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7dd91f2e-f3ce-43d4-a2a9-5a9040967080",
        "id": "Ls_TqvENlf0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_element=5\n",
        "input_sequence = np.asarray([list(X_test[test_element])])\n",
        "y_pred=model2.predict(input_sequence,verbose=1)\n",
        "print ('Input string: {} ...'.format(test_text[test_element]))\n",
        "print ('Sentiment for the input string: {} ...'.format(Sent_dic[np.argmax(y_pred)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 3ms/step\n",
            "Input string: intermittently pleasing but ...\n",
            "Sentiment for the input string: somewhat positive ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s84Z6CKzqngI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TeeJYoNrqtjT"
      },
      "source": [
        "###CNN +GRUModel\n",
        "## Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l8RxOMtWqtjU",
        "colab": {}
      },
      "source": [
        "def model_CNN_GRU():\n",
        "  model= Sequential()\n",
        "  model.add(Embedding(max_features,100,input_length=max_words))\n",
        "  model.add(Conv1D(64,kernel_size=3,padding='same',activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(GRU(128,return_sequences=True))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128,activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(5,activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wfc6a4CeqtjX"
      },
      "source": [
        "## Build and compile the CNN +GRU model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dfgfsjmaqtjX",
        "colab": {}
      },
      "source": [
        "model3 = model_CNN_GRU()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "46bc8df2-6325-47bb-82a3-07a717264399",
        "id": "h7fgqxY4qtjc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "model3.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 48, 100)           1373200   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 48, 64)            19264     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 24, 128)           74112     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 24, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               393344    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 1,860,565\n",
            "Trainable params: 1,860,565\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4dSggQsfqtjf"
      },
      "source": [
        "## Fetch saved model weights and load the weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9c05a2a8-6b99-47b0-fda3-09b3e62f252d",
        "id": "0Dv-RTb5qtjf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "#! wget https://github.com/rahulremanan/python_tutorial/raw/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
        "  \n",
        "try:\n",
        "  model3.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-20 13:28:12--  https://github.com/rahulremanan/python_tutorial/raw/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5 [following]\n",
            "--2019-05-20 13:28:12--  https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5673112 (5.4M) [application/octet-stream]\n",
            "Saving to: RT_LSTM.h5\n",
            "\n",
            "RT_LSTM.h5          100%[===================>]   5.41M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-20 13:28:13 (45.9 MB/s) - RT_LSTM.h5 saved [5673112/5673112]\n",
            "\n",
            "No model weights file: /content/RT_LSTM.h5 found ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6YVg4WHYqtjj"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "697a1e92-c991-45d3-ce5e-4363b42f3c3e",
        "id": "1O-dIb6xqtjk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%%time\n",
        "history3=model3.fit(X_train, \n",
        "                    y_train, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=epochs, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 124848 samples, validate on 31212 samples\n",
            "Epoch 1/3\n",
            "124848/124848 [==============================] - 67s 534us/step - loss: 1.0247 - acc: 0.5895 - val_loss: 0.8497 - val_acc: 0.6525\n",
            "Epoch 2/3\n",
            "124848/124848 [==============================] - 65s 517us/step - loss: 0.8083 - acc: 0.6680 - val_loss: 0.8118 - val_acc: 0.6681\n",
            "Epoch 3/3\n",
            "124848/124848 [==============================] - 65s 518us/step - loss: 0.7290 - acc: 0.6964 - val_loss: 0.8106 - val_acc: 0.6702\n",
            "CPU times: user 3min 59s, sys: 28.1 s, total: 4min 27s\n",
            "Wall time: 3min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ovJgxwpIqtjn"
      },
      "source": [
        "## Save the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "buFNH3VJqtjp",
        "colab": {}
      },
      "source": [
        "model3.save_weights(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "30XvSu8Wqtjt",
        "colab": {}
      },
      "source": [
        "files.download(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v23_td4Hqtju"
      },
      "source": [
        "## Load model weights from weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "876f813f-1354-44c4-fe79-1a4c8342225a",
        "id": "lFH659ZKqtjv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  model3.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model weights from: /content/RT_LSTM.h5 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_CCQfDyYqtjx"
      },
      "source": [
        "## Running model inference on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a11beda0-3466-4252-cc04-ca22533a9bcd",
        "id": "7Pc5oY3wqtjy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_element=5\n",
        "input_sequence = np.asarray([list(X_test[test_element])])\n",
        "y_pred=model3.predict(input_sequence,verbose=1)\n",
        "print ('Input string: {} ...'.format(test_text[test_element]))\n",
        "print ('Sentiment for the input string: {} ...'.format(Sent_dic[np.argmax(y_pred)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 1s 535ms/step\n",
            "Input string: intermittently pleasing but ...\n",
            "Sentiment for the input string: somewhat positive ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHfnzd5KzeA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YKczhMjuzrIR"
      },
      "source": [
        "###Bidirectional GRU\n",
        "## Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UZ_cIyy1zrIT",
        "colab": {}
      },
      "source": [
        "def model_BiDir_GRU():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(max_features, 100, input_length=max_words))\n",
        "  model.add(SpatialDropout1D(0.25))\n",
        "  model.add(Bidirectional(GRU(128)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(5, activation='softmax'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uxczg9H7zrIV"
      },
      "source": [
        "## Build and compile the Bidirectional GRU model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6N34Br9XzrIW",
        "colab": {}
      },
      "source": [
        "model4 = model_BiDir_GRU()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "95201724-6730-4109-e25c-9c9b2c1bb473",
        "id": "bixZioJuzrIa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model4.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 48, 100)           1373200   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 48, 100)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               175872    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 1,550,357\n",
            "Trainable params: 1,550,357\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8DUQFVoDzrIh"
      },
      "source": [
        "## Fetch saved model weights and load the weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9c05a2a8-6b99-47b0-fda3-09b3e62f252d",
        "id": "tphQHsyuzrIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "#! wget https://github.com/rahulremanan/python_tutorial/raw/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
        "  \n",
        "try:\n",
        "  model4.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-20 13:28:12--  https://github.com/rahulremanan/python_tutorial/raw/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5 [following]\n",
            "--2019-05-20 13:28:12--  https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5673112 (5.4M) [application/octet-stream]\n",
            "Saving to: RT_LSTM.h5\n",
            "\n",
            "RT_LSTM.h5          100%[===================>]   5.41M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-20 13:28:13 (45.9 MB/s) - RT_LSTM.h5 saved [5673112/5673112]\n",
            "\n",
            "No model weights file: /content/RT_LSTM.h5 found ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zeQrfZ5CzrIk"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "538f0e99-cbd9-4ec3-a64d-061b55f17f71",
        "id": "NtlLdZmTzrIl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%%time\n",
        "history4=model4.fit(X_train, \n",
        "                    y_train, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=epochs, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 124848 samples, validate on 31212 samples\n",
            "Epoch 1/3\n",
            "124848/124848 [==============================] - 205s 2ms/step - loss: 1.0004 - acc: 0.5973 - val_loss: 0.8515 - val_acc: 0.6540\n",
            "Epoch 2/3\n",
            "124848/124848 [==============================] - 204s 2ms/step - loss: 0.8017 - acc: 0.6708 - val_loss: 0.8165 - val_acc: 0.6677\n",
            "Epoch 3/3\n",
            "124848/124848 [==============================] - 202s 2ms/step - loss: 0.7376 - acc: 0.6952 - val_loss: 0.8059 - val_acc: 0.6720\n",
            "CPU times: user 14min 50s, sys: 2min 6s, total: 16min 57s\n",
            "Wall time: 10min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Jwgr8GpzrIo"
      },
      "source": [
        "## Save the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "loXEHHzMzrIo",
        "colab": {}
      },
      "source": [
        "model4.save_weights(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZDTRTUdzrIp",
        "colab": {}
      },
      "source": [
        "files.download(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EU5c7hrczrIt"
      },
      "source": [
        "## Load model weights from weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "876f813f-1354-44c4-fe79-1a4c8342225a",
        "id": "rcDYjKGIzrIu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  model4.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model weights from: /content/RT_LSTM.h5 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gRKIl5gjzrIz"
      },
      "source": [
        "## Running model inference on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1d08ac94-17f3-4781-8cad-976441512888",
        "id": "7fFSN6c_zrI0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_element=5\n",
        "input_sequence = np.asarray([list(X_test[test_element])])\n",
        "y_pred=model4.predict(input_sequence,verbose=1)\n",
        "print ('Input string: {} ...'.format(test_text[test_element]))\n",
        "print ('Sentiment for the input string: {} ...'.format(Sent_dic[np.argmax(y_pred)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 1s 727ms/step\n",
            "Input string: intermittently pleasing but ...\n",
            "Sentiment for the input string: neutral ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD1LSCaF3fvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfy1F7zyE-gU",
        "colab_type": "text"
      },
      "source": [
        "###Glove word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVyC1e3mE3of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word, *arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "    \n",
        "def get_embed_mat(EMBEDDING_FILE, max_features,embed_dim):\n",
        "    # word vectors\n",
        "    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n",
        "    print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "    # embedding matrix\n",
        "    word_index = tokenizer.word_index\n",
        "    num_words = min(max_features, len(word_index) + 1)\n",
        "    all_embs = np.stack(embeddings_index.values()) #for random init\n",
        "    embedding_matrix = np.random.normal(all_embs.mean(), all_embs.std(), \n",
        "                                        (num_words, embed_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    max_features = embedding_matrix.shape[0]\n",
        "    \n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q183LZhcFCCO",
        "colab_type": "code",
        "outputId": "5473b367-a3c9-42b3-9cf9-ab66fc8cd6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# embedding matrix\n",
        "EMBEDDING_FILE = '/content/glove.6B.100d.txt'\n",
        "embed_dim = 100 #word vector dim\n",
        "embedding_matrix = get_embed_mat(EMBEDDING_FILE,max_features,embed_dim)\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n",
            "(13732, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJYzpxQ6FbB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Sfpuu3NFwVS"
      },
      "source": [
        "\n",
        "## Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e2oYXBXiFwVU",
        "colab": {}
      },
      "source": [
        "def model_Glove():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True))\n",
        "  model.add(SpatialDropout1D(0.25))\n",
        "  model.add(Bidirectional(GRU(128,return_sequences=True)))\n",
        "  model.add(Bidirectional(GRU(64,return_sequences=False)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_rHCFKfRFwVX"
      },
      "source": [
        "## Build and compile the Bidirectional GRU model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cRkAubDrFwVY",
        "colab": {}
      },
      "source": [
        "model5 = model_Glove()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "33547730-4103-448f-b6be-9c2750f5bd82",
        "id": "1Sh6E7C8FwVZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model5.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 48, 100)           1373200   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 48, 100)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 48, 256)           175872    \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 128)               123264    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 1,672,981\n",
            "Trainable params: 1,672,981\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p3aRk1hRFwVd"
      },
      "source": [
        "## Fetch saved model weights and load the weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9c05a2a8-6b99-47b0-fda3-09b3e62f252d",
        "id": "2dnl8emJFwVe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "#! wget https://github.com/rahulremanan/python_tutorial/raw/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
        "  \n",
        "try:\n",
        "  model5.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-20 13:28:12--  https://github.com/rahulremanan/python_tutorial/raw/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5 [following]\n",
            "--2019-05-20 13:28:12--  https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/NLP/10-Sentiment_analysis/weights/RT_LSTM.h5\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5673112 (5.4M) [application/octet-stream]\n",
            "Saving to: RT_LSTM.h5\n",
            "\n",
            "RT_LSTM.h5          100%[===================>]   5.41M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-20 13:28:13 (45.9 MB/s) - RT_LSTM.h5 saved [5673112/5673112]\n",
            "\n",
            "No model weights file: /content/RT_LSTM.h5 found ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RLXySDBzFwVh"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4013b049-f585-4ddb-9840-5d4ff43f09df",
        "id": "kV3-xx_cFwVh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "%%time\n",
        "history5=model5.fit(X_train, \n",
        "                    y_train, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=4, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 124848 samples, validate on 31212 samples\n",
            "Epoch 1/4\n",
            "124848/124848 [==============================] - 385s 3ms/step - loss: 0.9975 - acc: 0.5892 - val_loss: 0.8393 - val_acc: 0.6508\n",
            "Epoch 2/4\n",
            "124848/124848 [==============================] - 378s 3ms/step - loss: 0.8466 - acc: 0.6487 - val_loss: 0.7938 - val_acc: 0.6716\n",
            "Epoch 3/4\n",
            "124848/124848 [==============================] - 378s 3ms/step - loss: 0.7864 - acc: 0.6741 - val_loss: 0.7723 - val_acc: 0.6797\n",
            "Epoch 4/4\n",
            "124848/124848 [==============================] - 380s 3ms/step - loss: 0.7473 - acc: 0.6889 - val_loss: 0.7623 - val_acc: 0.6840\n",
            "CPU times: user 36min 51s, sys: 4min 22s, total: 41min 13s\n",
            "Wall time: 25min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FyvimRuRFwVj"
      },
      "source": [
        "## Save the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZC02SludFwVk",
        "colab": {}
      },
      "source": [
        "model5.save_weights(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JtSKmVwDFwVm",
        "colab": {}
      },
      "source": [
        "files.download(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FWLfCznTFwVo"
      },
      "source": [
        "## Load model weights from weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "876f813f-1354-44c4-fe79-1a4c8342225a",
        "id": "Z-gZxtFJFwVo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  model5.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model weights from: /content/RT_LSTM.h5 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2aUoOlq_FwVq"
      },
      "source": [
        "## Running model inference on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "66ae87b9-f366-48f8-c598-6f25fd6ab919",
        "id": "5ea7TsEeFwVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_element=5\n",
        "input_sequence = np.asarray([list(X_test[test_element])])\n",
        "y_pred=model5.predict(input_sequence,verbose=1)\n",
        "print ('Input string: {} ...'.format(test_text[test_element]))\n",
        "print ('Sentiment for the input string: {} ...'.format(Sent_dic[np.argmax(y_pred)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 1s 1s/step\n",
            "Input string: intermittently pleasing but ...\n",
            "Sentiment for the input string: somewhat positive ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZS8-wVaGjyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPJ2stQgLU3p",
        "colab_type": "text"
      },
      "source": [
        "##Combine all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh83SKOdLX22",
        "colab_type": "code",
        "outputId": "aad0c21d-5934-46bd-be6a-79213d898979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "test_element=5\n",
        "input_sequence = np.asarray([list(X_test[test_element])])\n",
        "\n",
        "y_pred1=model1.predict(input_sequence,verbose=1)\n",
        "y_pred2=model2.predict(input_sequence,verbose=1)\n",
        "y_pred3=model3.predict(input_sequence,verbose=1)\n",
        "y_pred4=model4.predict(input_sequence,verbose=1)\n",
        "y_pred5=model5.predict(input_sequence,verbose=1)\n",
        "\n",
        "pred1=np.argmax(y_pred1)\n",
        "pred2=np.argmax(y_pred2)\n",
        "pred3=np.argmax(y_pred3)\n",
        "pred4=np.argmax(y_pred4)\n",
        "pred5=np.argmax(y_pred5)\n",
        "\n",
        "Sent_all=stats.mode([pred1,pred2,pred3,pred4,pred5],axis=0)[0][0]  \n",
        "\n",
        "print ('Input string: {} ...'.format(test_text[test_element]))\n",
        "print ('Sentiment for the input string: {} ...'.format(Sent_dic[Sent_all]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "Input string: intermittently pleasing but ...\n",
            "Sentiment for the input string: somewhat positive ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2I-sOXHYSSY",
        "colab_type": "code",
        "outputId": "f1aa5247-5b1a-4f73-b2a5-028079003703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.54257699e-04, 1.35154305e-02, 4.51130331e-01, 5.23305535e-01,\n",
              "        1.17944321e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FeHLEhLY4lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mod()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}