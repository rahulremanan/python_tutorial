-- Nvidia machine learning libraries --

https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/

-- Update and upgrade --

$ sudo apt-get update
$ sudo apt-get upgrade

-- Verify CUDA capability --

$ sudo apt install pciutils 
$ lspci | grep -i nvidia

-- Verify linux version support --

$ uname -m && cat /etc/*release

-- Install dependencies --

$ sudo apt install -y build-essential dkms freeglut3 freeglut3-dev libxi-dev libxmu-dev cmake git unzip zip pylint pkg-config g++ zlib1g-dev python python3-numpy python3-dev python3-pip python3-wheel

-- Install linux kernel header --

$ uname -r
$ sudo apt-get install linux-headers-$(uname -r)

-- Auto remove un-necessary packages --

$ sudo apt autoremove

-- Fetch CUDA 10 installer file --

$ wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin
$ sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600
$ wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb
$ sudo dpkg -i cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb
$ sudo apt-key add /var/cuda-repo-10-2-local-10.2.89-440.33.01/7fa2af80.pub

-- Install CUDA 10.2 --
$ sudo apt update
$ sudo apt install cuda

-- Verify CUDA installation --

$ echo 'export PATH=/usr/local/cuda-10.2/bin${PATH:+:${PATH}}' >> ~/.bashrc
$ echo 'export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}' >> ~/.bashrc
$ source ~/.bashrc
$ ldconfig
$ nvidia-smi

nvcc -V
-- Install TesnorRT 7.0.0.11 GA --
(https://docs.nvidia.com/deeplearning/sdk/tensorrt-install-guide/index.html)

Download tensorrt installer from https://developer.nvidia.com/nvidia-tensorrt-5x-download

$ wget <--download link--> -O nv-tensorrt-repo-ubuntu1910-cuda10.2-trt7.0.0-ga-20200216_1-1_amd64.deb

$ sudo dpkg -i nv-tensorrt-repo-ubuntu1910-cuda10.2-trt7.0.0-ga-20200216_1-1_amd64.deb
$ sudo apt-key add /var/nv-tensorrt-repo-cuda10.2-trt7.0.0-ga-20191216/7fa2af80.pub
$ sudo apt-get update
$ sudo apt-get install -y tensorrt

$ sudo apt install libnvinfer7 libnvonnxparsers7 libnvparsers7 \
                   libnvinfer-plugin7 libnvinfer-dev libnvonnxparsers-dev \
                   libnvparsers-dev libnvinfer-plugin-dev

$ sudo python3 -m pip install pycuda

-- Install libnvinfer, uff-converter-tf, graphsurgeon-tf --

$ sudo apt install -y python3-libnvinfer-dev uff-converter-tf

find ~/ -type f -name "libnvinfer"

-- Verify TensorRT installation --

$ dpkg -l | grep TensorRT

-- Install cuDNN 7.6.5 --

$ wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/libcudnn7-dev_7.6.5.32-1+cuda10.2_amd64.deb -O libcudnn7-dev_7.6.5.32-1+cuda10.2_amd64.deb
$ sudo dpkg -i libcudnn7-dev_7.6.5.32-1+cuda10.2_amd64.deb
$ sudo apt update
$ sudo apt install -y libcudnn7-dev

-- Install NCCL 2.5.6 --

$ wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/libnccl-dev_2.5.6-1+cuda10.2_amd64.deb -O libnccl-dev_2.5.6-1+cuda10.2_amd64.deb 
$ sudo dpkg -i libnccl-dev_2.5.6-1+cuda10.2_amd64.deb 
$ wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/libnccl2_2.5.6-1+cuda10.2_amd64.deb -O libnccl2_2.5.6-1+cuda10.2_amd64.deb
$ sudo dpkg -i libnccl2_2.5.6-1+cuda10.2_amd64.deb
$ sudo apt-get update
$ sudo apt install -y libnccl2 libnccl-dev

-- Install lincupti --

$ sudo apt-get install -y libcupti-dev
$ echo 'export LD_LIBRARY_PATH=/usr/local/cuda-10.2/extras/CUPTI/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
$ source ~/.bashrc
$ sudo ldconfig

-- Edit CUDA 10.2 host_config.h file for gcc version >8 support --

$ sudo nano /usr/local/cuda/include/crt/host_config.h


#if defined(__GNUC__)

#if __GNUC__ > 8

//#error -- unsupported GNU version! gcc versions later than 8 are not supported!

#endif /* __GNUC__ > 8 */

-- Edit Tensorflow source for NCCL support --

$ sudo nano ./third_party/nccl/build_defs.bzl.tpl

-- Edit workspace.bzl for grpc patch --

$ sudo nano ./tensorflow/workspace.bzl

Alt + G 486

Change this section:

tf_http_archive(
        name = "grpc",
        sha256 = "67a6c26db56f345f7cee846e681db2c23f919eba46dd639b09462d1b6203d28c",
        strip_prefix = "grpc-4566c2a29ebec0835643b972eb99f4306c4234a3",
        system_build_file = clean_dep("//third_party/systemlibs:grpc.BUILD"),
        urls = [
            "https://storage.googleapis.com/mirror.tensorflow.org/github.com/grpc/grpc/archive/4566c2a29ebec0835643b972eb9>
            "https://github.com/grpc/grpc/archive/4566c2a29ebec0835643b972eb99f4306c4234a3.tar.gz",
        ],
    )

to:

tf_http_archive(
        name = "grpc",
        patch_file = clean_dep("//third_party:Rename-gettid-functions_grpc.patch"),
        sha256 = "67a6c26db56f345f7cee846e681db2c23f919eba46dd639b09462d1b6203d28c",
        strip_prefix = "grpc-4566c2a29ebec0835643b972eb99f4306c4234a3",
        system_build_file = clean_dep("//third_party/systemlibs:grpc.BUILD"),
        urls = [
            "https://storage.googleapis.com/mirror.tensorflow.org/github.com/grpc/grpc/archive/4566c2a29ebec0835643b972eb9>
            "https://github.com/grpc/grpc/archive/4566c2a29ebec0835643b972eb99f4306c4234a3.tar.gz",
        ],
    )


remove the line "--bin2c-path=%s" % bin2c.dirname 

-- Get the grpc patch --
$ cd ./third_party
$ wget <Rename-gettid-functions_grpc.patch URL> -O Rename-gettid-functions_grpc.patch
$ cd ..
-- Edit configure.py for Bazel 2.1.0 support --

$ sudo nano ./configure.py

edit this line to: _TF_MAX_BAZEL_VERSION = '2.1.0'

-- Install tensorflow dependencies--

$ sudo python3 -m pip install keras_applications --no-deps keras_preprocessing --no-deps h5py scipy matplotlib

-- Install bazel using bootstrap method --

# Instructions to build the build tool that buildscp Tensorflow
-- Install Tensorflow dependencies --

$ sudo apt-get update
$ sudo apt install python-dev python-pip python3-dev python3-pip
$ sudo pip3 install -U --user pip six numpy wheel setuptools mock 'future>=0.17.1'
$ sudo pip3 install -U --user keras_applications --no-deps keras_preprocessing --no-deps

-- Install Bazel build dependencies --

$ sudo apt install g++ unzip zip openjdk-11-jdk

# Build Bazel using Bootstrap technique

-- Download and extract Bazel dist (architecture independent) zip file --

$ sudo wget https://github.com/bazelbuild/bazel/releases/download/2.1.0/bazel-2.1.0-dist.zip -O bazel.zip
$ sudo mkdir ./bazel
$ sudo unzip ./bazel.zip -d ./bazel

-- Build Bazel --
$ cd ./bazel
$ sudo env EXTRA_BAZEL_ARGS="--host_javabase=@local_jdk//:jdk" bash ./compile.sh

-- Copy the bazel binary --

$ sudo cp output/bazel /usr/local/bin/

-- Check Bazel version --

$ bazel --version

# Verify bazel installation:

$ bazel

-- Removing bazel --

$ sudo rm $HOME/.cache/bazel -fr
$ sudo rm /usr/local/bin/bazel /etc/bazelrc /home/rahul/bin/bazel /etc/bazel.bazelrc /usr/local/lib/bazel -fr

-- Fetch and configure tensorflow --

$ cd ~/
$ git clone https://github.com/tensorflow/tensorflow.git
$ cd tensorflow
$ git pull
$ git checkout 

-- For a specific tensorflow version --

$ git checkout r2.1

$ ./configure

-- Sample configuration --

Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3


Found possible Python library paths:  /usr/local/lib/python3.7/dist-packages  /usr/lib/python3/dist-packagesPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.7/dist-packages]

Do you wish to build TensorFlow with XLA JIT support? [Y/n]:
XLA JIT support will be enabled for TensorFlow.Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]:No OpenCL SYCL support will be enabled for TensorFlow.
Do you wish to build TensorFlow with ROCm support? [y/N]:
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: Y
CUDA support will be enabled for TensorFlow.Do you wish to build TensorFlow with TensorRT support? [y/N]:No TensorRT support will be enabled for TensorFlow.

Found CUDA 10.2 in:
    /usr/local/cuda/lib64    /usr/local/cuda/include
Found cuDNN 7 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 7.5]:


Do you want to use clang as CUDA compiler? [y/N]:
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:


Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native -Wno-sign-compare]:


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]:
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding "--config=<>" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
        --config=ngraph         # Build with Intel nGraph support.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=nonccl         # Disable NVIDIA NCCL support.
Configuration finished

-- Build tensorflow using bazel --

$ bazel build --config=opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package

add "--config=mkl" (For Intel MKL support for newer intel cpu for faster training on cpu)
add "--config=monolithic" (For static monolithic build. Try this option if a build fails.)
add "--local_resources 2048,.5,1.0" (For devices with low ram causing Segmentation fault or other related errors.)

-- Build tensorflow using bazel for Intel Haswell using CUDA 10 --

$ sudo bazel build -c opt --copt=-march="haswell" --config=cuda //tensorflow/tools/pip_package:build_pip_package

-- Build python wheel installer --

$ sudo bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
$ sudo python3 -m pip install /tmp/tensorflow_pkg/tensorflow-*.whl

-- Setup tensorflow for Julia --

$ bazel build --config=opt //tensorflow:libtensorflow.so --config=cuda

-- Copy libtensorflow.so to julia packages folder --

$ cd ./bazel-bin/tensorflow
$ sudo su
$ mkdir /etc/tensorflow/
$ cp ./libtensorflow.so /etc/tensorflow/
$ cp ./libtensorflow_framework.so /etc/tensorflow/

--Setup a virtual environment --

$ sudo apt-get install virtualenv
$ virtualenv tf_1.11.0_cuda10.0 -p /usr/bin/python3
$ source tf_1.11.0_cuda10.0/bin/activate
$ python3 -m pip install ./tmp/tensorflow_pkg/tensorflow*.whl

-- Verify tensorflow installation --

$ python
(Run this inside python interpreter)
>>>import tensorflow as tf
>>>hello = tf.constant('Hello, TensorFlow!')
>>>sess = tf.Session()
>>>print(tf.__version__)
>>>print(sess.run(hello))
>>>print(tf.test.gpu_device_name())
>>>from tensorflow.python.client import device_lib
>>>print(device_lib.list_local_devices())

-- Keras installation --

$ git clone https://github.com/keras-team/keras.git
$ cd keras
$ git checkout
$ sudo python3 setup.py install
$ python3 -c "import keras"
