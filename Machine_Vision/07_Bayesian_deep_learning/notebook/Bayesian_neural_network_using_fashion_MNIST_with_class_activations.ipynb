{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCFgEF6wMecv"
      },
      "source": [
        "\n",
        "# Bayesian deep-learning\n",
        "\n",
        "### Author: [Dr. Rahul Remanan](https://linkedin.com/in/rahulremanan); CEO, [Moad Computer](https://moad.computer)\n",
        "### Contact: rahul@moad.computer\n",
        "\n",
        "### [Launch in Google Colab](https://colab.research.google.com/drive/1W-lTnsAvb8paJK7SB8WeUecIQRx3F0tN)\n",
        "\n",
        "Bayesian deep-learning network using [dropout layers to perform Monte Carlo approximations](https://arxiv.org/pdf/1506.02142.pdf) for quantifying model uncertainty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNo1Vfghpa8j"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This notebook uses the fashion MNIST dataset and a Bayesain deep-learning model. If the Google Cloud TPU is attached to the notebook, the model can utilize the TPU to accelerate the training and inference performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgAHfQtuhddd"
      },
      "source": [
        "# Learning goals\n",
        "\n",
        "*   Build a Bayesian deep-learning network in Keras\n",
        "*   Create and compile the model under a distribution strategy that uses TPUs\n",
        "*   Run Bayesian inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrprJD-R-410"
      },
      "source": [
        "# Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I0RdnOSkNmi"
      },
      "source": [
        "<h3>  &nbsp;&nbsp;Train on Google Colab using TPU&nbsp;&nbsp; <a href=\"https://colab.research.google.com/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/rahulremanan/python_tutorial/master/Machine_Vision/07_Bayesian_deep_learning/media/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eEM-XOvURoU"
      },
      "source": [
        "## A quick word about TPUs\n",
        "\n",
        "TPUs are currently available only in the Google Cloud. They are designed to read the data directly from Google Cloud Storage (GCS). Therefore, local datasets need to be either stored in the cloud instance memory to pass it to the TPU or as a GCS bucket so that the TPU can access it. For developers, this means that the typical generator functions that can handle CPUs or GPUs will therefore fail when trying to use TPUs, necessitating custom TPU specific generator functions. In this notebook, we are using the first approach by storing the entire fashion MNIST dataset in the instance memory. This approach of handling the dataset without a generator function works well in this particular case due to the manageable size of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edfbxDDh2AEs"
      },
      "source": [
        "# Bayesian deep-learning using Fashion MNIST, Keras and TPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install HandBrake for transcoding video"
      ],
      "metadata": {
        "id": "vj6pprgzauuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!apt install -y handbrake handbrake-cli"
      ],
      "metadata": {
        "id": "-AijKIzqayzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT6wk8fu5kUh"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03EV61RS5jyR"
      },
      "source": [
        "import os, cv2, time, sys, glob, requests, \\\n",
        "       numpy as np, tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "%matplotlib inline\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ0ApHYzymwL"
      },
      "source": [
        "## Specify variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okc0HLK3gIFA"
      },
      "source": [
        "WEIGHTS_FILE='./bayesian_fashionMNIST.h5'\n",
        "GITHUB_REPO='https://github.com/rahulremanan/python_tutorial/'\n",
        "WEIGHTS_URL='{}raw/master/Machine_Vision/07_Bayesian_deep_learning/weights/bayesian_fashionMNIST.h5'.format(GITHUB_REPO)\n",
        "LABEL_NAMES = ['t_shirt','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle_boots']\n",
        "\n",
        "ENABLE_TRAINING = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvo0t7XVIkWZ"
      },
      "source": [
        "# Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MICrRv8rmXVq"
      },
      "source": [
        "The fashion MNIST dataset is available as a `tf.keras.datasets`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo-Yk6LFGfSf"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgc2FZKVMx15"
      },
      "source": [
        "# Define the Bayesian deep-learning model\n",
        "\n",
        "The following example uses a single layer conv-net with a dropout layer for doing the Monte Carlo approximations during Bayesian inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URGDYrzsXZ5p"
      },
      "source": [
        "def fashionMNIST_model(input_data, dropout_rate=0.5,\n",
        "                       model_name=\"Bayesian_fashionMNIST\",\n",
        "                       enable_bayesian_inference=True):\n",
        "  inputs = tf.keras.Input(shape=(input_data.shape[1:]))\n",
        "  x = tf.keras.layers.Conv2D(128, (3,3), name='Conv2D')(inputs)\n",
        "  x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2),\n",
        "                                   name='MaxPool2D')(x)\n",
        "  x = tf.keras.layers.Activation('elu')(x)\n",
        "  x = tf.keras.layers.Dropout(dropout_rate)(x,\n",
        "                          training=enable_bayesian_inference)\n",
        "  x = tf.keras.layers.Flatten(name='Flatten')(x)\n",
        "  x = tf.keras.layers.Dense(10, name='Predictions')(x)\n",
        "  outputs = tf.keras.layers.Activation('softmax')(x)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLeZATVaNAnE"
      },
      "source": [
        "# Using the TPU\n",
        "\n",
        "To use the TPU for training and inference, first the TPU device needs to be initialized. Then the model has to be built and compiled specifically to use the TPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhF9VAoDaCBf"
      },
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  print('Running on TPU ...')\n",
        "\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "  strategy = tf.distribute.TPUStrategy(tpu)\n",
        "  print('Replicas: ', strategy.num_replicas_in_sync)\n",
        "except ValueError:\n",
        "  tpu, strategy = None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWEYmd_hIWg8"
      },
      "source": [
        "if strategy is not None:\n",
        "  with strategy.scope():\n",
        "    bayesian_model = fashionMNIST_model(x_train, enable_bayesian_inference=True)\n",
        "    bayesian_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                           loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                           metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "else:\n",
        "  bayesian_model = fashionMNIST_model(x_train, enable_bayesian_inference=True)\n",
        "  bayesian_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                         loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                         metrics=[tf.keras.metrics.sparse_categorical_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bayesian_model.summary()"
      ],
      "metadata": {
        "id": "3vHIY7kRC-54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijs_8CF6fh4g"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s0KFzjsfyy0"
      },
      "source": [
        "## Download pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJxykSFfpDjK"
      },
      "source": [
        "if not os.path.exists(WEIGHTS_FILE):\n",
        "  !wget {WEIGHTS_URL} -O {WEIGHTS_FILE}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef7q0gN9ftuI"
      },
      "source": [
        "if os.path.exists(WEIGHTS_FILE):\n",
        "  bayesian_model.load_weights(WEIGHTS_FILE)\n",
        "  print('Loaded pre-trained weights: {} ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_KxMOKssXL7"
      },
      "source": [
        "## Training the fashion MNIST Bayesian deep-learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjps3-L_55qt"
      },
      "source": [
        "if ENABLE_TRAINING:\n",
        "  bayesian_model.fit(x_train.astype(np.float32),y_train.astype(np.float32),\n",
        "                     epochs=5,\n",
        "                     steps_per_epoch=60,\n",
        "                     validation_data=(x_test.astype(np.float32),\n",
        "                                      y_test.astype(np.float32)),\n",
        "                     validation_freq=1)\n",
        "\n",
        "  bayesian_model.save_weights(WEIGHTS_FILE, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESL6ltQTMm05"
      },
      "source": [
        "# Bayesian inference\n",
        "The inference step is repeated over and over again to obtain the model uncertainty associated with each prediction class. Unlike in the regular deep-learning architecture, each inference step returns a different set of probabilities for each class. The final accuracy is calculated as the class-wise mean of all the probabilities. The model uncertainty is numerically represented as the class-wise standard deviation of all the probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykP4GEcIbouc"
      },
      "source": [
        "if strategy is not None:\n",
        "  with strategy.scope():\n",
        "    bayesian_model = fashionMNIST_model(x_train, enable_bayesian_inference=True)\n",
        "    bayesian_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                           loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                           metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "else:\n",
        "  bayesian_model = fashionMNIST_model(x_train, enable_bayesian_inference=True)\n",
        "  bayesian_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                         loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                         metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "bayesian_model.load_weights(WEIGHTS_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCSwYweKcPjq"
      },
      "source": [
        "preds=[]\n",
        "num_bayesian_inference_steps=10\n",
        "for i in tqdm(range(num_bayesian_inference_steps)):\n",
        "  preds.append(bayesian_model.predict(x_test[:16].astype(np.float32)))\n",
        "mean_preds=np.mean(np.asarray(preds), axis=0)\n",
        "stdev_preds=np.std(np.asarray(preds), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IExxHPhOvfDp"
      },
      "source": [
        "## Visualize predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwpJf7xeb4u-"
      },
      "source": [
        "def plot_predictions(images, ground_truths, preds_acc,\n",
        "                     preds_stdev=None, label_names=None,\n",
        "                     enable_bayesian_inference=True):\n",
        "  n = images.shape[0]\n",
        "  nc = int(np.ceil(n / 4))\n",
        "  f, axes = plt.subplots(nc, 4)\n",
        "  for i in range(nc * 4):\n",
        "    y = i // 4\n",
        "    x = i % 4\n",
        "    axes[x, y].axis('off')\n",
        "\n",
        "    label = label_names[np.argmax(preds_acc[i])]\n",
        "    ground_truth=label_names[ground_truths[i]]\n",
        "    accuracy = np.max(preds_acc[i])\n",
        "    if enable_bayesian_inference and preds_stdev is not None:\n",
        "      confidence = preds_stdev[i][np.argmax(preds_acc[i])]\n",
        "\n",
        "    if i > n:\n",
        "      continue\n",
        "    axes[x, y].imshow(images[i])\n",
        "    if enable_bayesian_inference and preds_stdev is not None:\n",
        "      axes[x, y].text(0.5,0.5, '\\nLabel (Actual): {} ({})'.format(label,ground_truth) +\n",
        "                               '\\nAccuracy: {}, \\nUncertainty: {}\\n'.format(str(round(accuracy,2)),\n",
        "                                                                            str(round(confidence,2))),\n",
        "                      fontsize=10)\n",
        "    else:\n",
        "      axes[x, y].text(0.5,0.5, '\\nLabel: {}'.format(label) +\n",
        "                               '\\nAccuracy: {} \\n'.format(str(round(accuracy,2))),\n",
        "                      fontsize=10)\n",
        "    plt.gcf().set_size_inches(16,16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "Ba1yXo02KB7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaYPv_aKId2d"
      },
      "source": [
        "plot_predictions(np.squeeze(x_test[:16]), y_test[:16],\n",
        "                 mean_preds, stdev_preds,\n",
        "                 label_names=LABEL_NAMES,\n",
        "                 enable_bayesian_inference=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing uncertainty -- Bayesian class activation maps"
      ],
      "metadata": {
        "id": "zLKvTEEOVaku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_featureSizeExtractor(last_conv_layer):\n",
        "  try:\n",
        "    if len(last_conv_layer.output.get_shape().as_list()) == 4:\n",
        "      feature_size = last_conv_layer.output.get_shape().as_list()[3]\n",
        "      return feature_size\n",
        "    else:\n",
        "      print ('Received tensor shape: {} instead of expected shape: 4'.format(len(last_conv_layer.output.get_shape().as_list())))\n",
        "      return None\n",
        "  except AttributeError:\n",
        "    if len(last_conv_layer.output.shape) == 4:\n",
        "      feature_size = list(last_conv_layer.output.shape)[3]\n",
        "      return feature_size\n",
        "    else:\n",
        "      print ('Received tensor shape: {} instead of expected shape: 4'.format(len(last_conv_layer.output.shape)))\n",
        "      return None"
      ],
      "metadata": {
        "id": "5UhKdAWZAx12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process_input_image(input_image_file,\n",
        "                            image_height,\n",
        "                            image_width,\n",
        "                            pre_processor=None,\n",
        "                            url_mode=False,\n",
        "                            file_mode=False):\n",
        "  if input_image_file is None:\n",
        "    print ('No input file specified to generate predictions ...')\n",
        "    return\n",
        "\n",
        "  if url_mode:\n",
        "    response = requests.get(input_image_file)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img = img.resize((image_width, image_height))\n",
        "  elif file_mode:\n",
        "    img = input_image_file\n",
        "  else:\n",
        "    img = tf.keras.preprocessing.image.load_img(input_image_file, target_size=(image_width, image_height))\n",
        "\n",
        "  x = img\n",
        "\n",
        "  if not file_mode:\n",
        "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    x= np.sum(x, axis=-1)\n",
        "    x = (x - np.min(x))/(np.max(x) - np.min(x))\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    if pre_processor !=None:\n",
        "      x = pre_processor(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "4iHCUN6ob_Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_array(img_path, size):\n",
        "    img = tf.keras.utils.load_img(img_path, target_size=size)\n",
        "    array = tf.keras.utils.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, grad_cam_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        model.inputs, [model.get_layer(grad_cam_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy(), preds.numpy()"
      ],
      "metadata": {
        "id": "acVIoJE0r_IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bayesian_class_activation_map(input_image_file=None,\n",
        "                                  pre_processor=None,\n",
        "                                  label_decoder=None,\n",
        "                                  model=None,\n",
        "                                  labels=None,\n",
        "                                  image_width=299,\n",
        "                                  image_height=299,\n",
        "                                  gradcam_conv_layer='conv_7b',\n",
        "                                  url_mode=False,\n",
        "                                  file_mode=False,\n",
        "                                  eval_steps=10,\n",
        "                                  benchmark=True):\n",
        "  \"\"\"\n",
        "     A function to visualize class activation maps.\n",
        "\n",
        "     Also generate a Bayesian class activation map, that outputs a list of\n",
        "     heatmaps summarizing the model uncertainty.\n",
        "\n",
        "     GradCAMS are generated using Keras 3 example notebook: https://keras.io/examples/vision/grad_cam/\n",
        "  \"\"\"\n",
        "  x = pre_process_input_image(\n",
        "        input_image_file=input_image_file,\n",
        "        image_height=image_height,\n",
        "        image_width=image_width,\n",
        "        pre_processor=pre_processor,\n",
        "        url_mode=url_mode,\n",
        "        file_mode=file_mode\n",
        "      )\n",
        "\n",
        "  model = model\n",
        "  if model == None:\n",
        "    print ('No input model specified to generate predictions ...')\n",
        "    return\n",
        "  labels = labels\n",
        "\n",
        "  heatmaps      = []\n",
        "  iterate_input = []\n",
        "  pred_labels   = []\n",
        "  out_labels    = []\n",
        "\n",
        "  probabilities = np.empty((0,len(labels)), float)\n",
        "  print(probabilities)\n",
        "\n",
        "  for step in (range(eval_steps)):\n",
        "    startTime = time.time()\n",
        "    input_img = x\n",
        "    heatmap, preds = make_gradcam_heatmap(x, model, gradcam_conv_layer)\n",
        "    heatmaps.append(heatmap)\n",
        "    probability = preds.flatten()\n",
        "    probabilities = np.append(probabilities,\n",
        "                              np.array([probability]),\n",
        "                              axis=0)\n",
        "\n",
        "    if labels !=None:\n",
        "      pred_label = labels[np.argmax(probability)]\n",
        "      pred_labels.append(pred_label)\n",
        "      out_labels.append(pred_label)\n",
        "      print('PREDICTION: {}'.format(pred_label))\n",
        "      print('ACCURACY: {}'.format(preds[0]))\n",
        "      del pred_label\n",
        "    elif label_decoder !=None:\n",
        "      pred_label = pd.DataFrame(label_decoder(preds, top=3)[0],\n",
        "                                columns=['col1',\n",
        "                                         'category',\n",
        "                                         'probability']).iloc[:,1:]\n",
        "      pred_labels.append(pred_label.loc[0,'category'])\n",
        "      out_labels.append(pred_label.loc[0,'category'])\n",
        "      print('PREDICTION:', pred_label.loc[0,'category'])\n",
        "      del pred_label\n",
        "    else:\n",
        "      print ('No labels will be generated ...')\n",
        "\n",
        "    pred_labels = set(pred_labels)\n",
        "    pred_labels = list(pred_labels)\n",
        "    argmax = np.argmax(probability)\n",
        "    endTime = time.time()\n",
        "    executionTime = endTime - startTime\n",
        "\n",
        "    if benchmark:\n",
        "      print ('Completed processing {} out of {} steps in {} seconds ...'.format(int(step+1), int(eval_steps), float(executionTime)))\n",
        "  if eval_steps > 1:\n",
        "    heatmap_sum = heatmaps[0]\n",
        "    for i in range(len(heatmaps)-1):\n",
        "      if i<= len(heatmaps):\n",
        "        heatmap_sum = np.nan_to_num(heatmaps[i+1])+np.nan_to_num(heatmap_sum)\n",
        "    print (heatmap_sum)\n",
        "    mean_heatmap = heatmap_sum/len(heatmaps)\n",
        "  else:\n",
        "    mean_heatmap = heatmap\n",
        "\n",
        "  mean = np.matrix.mean(np.asmatrix(probabilities), axis=0)\n",
        "  stdev = np.matrix.std(np.asmatrix(probabilities), axis=0)\n",
        "\n",
        "  accuracy = np.matrix.tolist(mean)[0][np.argmax(mean)]\n",
        "  uncertainty = np.matrix.tolist(stdev)[0][np.argmax(mean)]\n",
        "\n",
        "  return [mean_heatmap, accuracy, uncertainty, pred_labels, heatmaps, out_labels, probabilities]"
      ],
      "metadata": {
        "id": "BtKjARIw_0Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heatmap_overlay(img, heatmap, threshold=0.8, read_file=True):\n",
        "  if read_file:\n",
        "    img = cv2.imread(img)\n",
        "  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "  heatmap = np.uint8(255*heatmap)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "  hif = threshold\n",
        "  superimposed_img = cv2.addWeighted(img, threshold, heatmap, 1-threshold, 0)\n",
        "  return superimposed_img, heatmap"
      ],
      "metadata": {
        "id": "OIY9fPqYPWBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bayesian_cam = True\n",
        "IMG_URL = 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Reebok_Royal_Glide_Ripple_Clip_shoe.jpg/440px-Reebok_Royal_Glide_Ripple_Clip_shoe.jpg'"
      ],
      "metadata": {
        "id": "Y9bH9ySdHLjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget {IMG_URL}\n",
        "INPUT_IMAGE_FILE = './440px-Reebok_Royal_Glide_Ripple_Clip_shoe.jpg'"
      ],
      "metadata": {
        "id": "kMhf5bUGIv48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize input image"
      ],
      "metadata": {
        "id": "SxH8K5GEXj2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = tf.keras.preprocessing.image.load_img(INPUT_IMAGE_FILE, target_size=(x_test.shape[1], x_test.shape[2]))\n",
        "x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "print(x.shape)\n",
        "print(np.max(x), np.min(x))\n",
        "x= np.sum(x, axis=-1)\n",
        "x = (x - np.min(x))/(np.max(x) - np.min(x))\n",
        "plt.imshow(x)"
      ],
      "metadata": {
        "id": "ehsDfB0NXi9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bayesian_model = fashionMNIST_model(x_train, enable_bayesian_inference=True)\n",
        "bayesian_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
        "    )\n",
        "bayesian_model.load_weights(WEIGHTS_FILE)"
      ],
      "metadata": {
        "id": "8p0U0rVjM1hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_layers = ['Conv2D', 'MaxPool2D']"
      ],
      "metadata": {
        "id": "l9XNGk6-dH6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if bayesian_cam:\n",
        "  outputs = []\n",
        "  for visualizer_layer in visualize_layers:\n",
        "    output = bayesian_class_activation_map(input_image_file=INPUT_IMAGE_FILE,\n",
        "                                           url_mode=False,\n",
        "                                           file_mode=False,\n",
        "                                           pre_processor=None,\n",
        "                                           model=bayesian_model,\n",
        "                                           labels=LABEL_NAMES,\n",
        "                                           image_width=x_test.shape[1],\n",
        "                                           image_height=x_test.shape[2],\n",
        "                                           gradcam_conv_layer=visualizer_layer,\n",
        "                                           eval_steps=100)\n",
        "    print (output[3])\n",
        "    outputs.append(output)"
      ],
      "metadata": {
        "id": "ZtUEmPaHFFzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, v in enumerate(visualize_layers):\n",
        "  HEATMAP = outputs[i][0]\n",
        "\n",
        "  plt.matshow(HEATMAP)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "X6IT_9ScdxLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if bayesian_cam:\n",
        "  for i, v in enumerate(visualize_layers):\n",
        "    output = outputs[i]\n",
        "    heatmaps=output[4]\n",
        "    labels=output[5]\n",
        "    img_array = []\n",
        "\n",
        "    for i in range(len(heatmaps)):\n",
        "      h_map = heatmaps[i]\n",
        "      LABEL = labels[i]\n",
        "      heatmap_output = heatmap_overlay(INPUT_IMAGE_FILE, h_map, threshold=0.7)\n",
        "      height, width, layers = heatmap_output[0].shape\n",
        "      size = (width, height)\n",
        "      superimposed_img = heatmap_output[0]\n",
        "      font = cv2.FONT_HERSHEY_DUPLEX\n",
        "      cv2.putText(superimposed_img,'{}'.format(LABEL),(10,50), font, 2,(255,255,255),2)\n",
        "      img_array.append(np.uint8(superimposed_img))\n",
        "\n",
        "    out = cv2.VideoWriter(f'bayesian_class_activation_maps_{v}.avi',\n",
        "                          cv2.VideoWriter_fourcc(*'DIVX'), 8, size)\n",
        "\n",
        "    for i in range(len(img_array)):\n",
        "      out.write(img_array[i])\n",
        "    out.release()"
      ],
      "metadata": {
        "id": "k584Z2IkEQK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "for v in visualize_layers:\n",
        "  !HandBrakeCLI -i ./bayesian_class_activation_maps_{v}.avi \\\n",
        "                -o ./bayesian_class_activation_maps_{v}.mp4 \\\n",
        "                -e x264 \\\n",
        "                -q 22   \\\n",
        "                -r 15   \\\n",
        "                -B 64   \\\n",
        "                -X 480  \\\n",
        "                -O"
      ],
      "metadata": {
        "id": "0DNreCHcR0UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "for v in visualize_layers:\n",
        "  video = io.open(f'./bayesian_class_activation_maps_{v}.mp4', 'r+b').read()\n",
        "  encoded = base64.b64encode(video)\n",
        "  display(HTML(data='''<video alt=\"test\" controls>\n",
        "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                 </video>'''.format(encoded.decode('ascii'))))"
      ],
      "metadata": {
        "id": "x0DduYz7R6De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaBH-qkCurwA"
      },
      "source": [
        "# Learning tasks:\n",
        "* Compare and contrast a regular deep-learning architecture and the Bayesian deep-learning architecture described in this notebook\n",
        "* Implement a regular inference (non-Bayesian) using the same model architecture and model weights used in this notebook\n",
        "* Describe why it is important to visualize uncertainty\n",
        "* The limitations of describing model uncertainty using just descriptive statistics\n",
        "* Anscombe's quartet and the importance of visual tools such as Bayesian class activation maps described in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o3VU0jTrD0e"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}