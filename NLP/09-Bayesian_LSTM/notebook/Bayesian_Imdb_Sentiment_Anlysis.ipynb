{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian_Imdb_Sentiment_Anlysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "RirOCElvDuzl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bayesian Sentiment analysis using recurrent neural networks\n",
        "\n",
        "## Author: [Dr. Rahul Remanan](https://www.linkedin.com/in/rahulremanan)\n",
        "## CEO and Chief Imagination Officer, [Moad Computer](https://moad.computer)"
        
        "### [Launch this notebook in Google CoLab](https://colab.research.google.com/github/rahulremanan/python_tutorial/blob/master/NLP/09-Bayesian_LSTM/notebook/Bayesian_Imdb_Sentiment_Anlysis.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "4bQdziBaDrxT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ]
    },
    {
      "metadata": {
        "id": "1ySX-lfDDrxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fb9567a-d3b8-4572-b06c-8113afac94e3"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy \n",
        "from keras import Model\n",
        "from keras.datasets import imdb \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten, LSTM \n",
        "from keras.layers.embeddings import Embedding \n",
        "from keras.preprocessing import sequence "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kXp50jjKDrxl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import data"
      ]
    },
    {
      "metadata": {
        "id": "rmHPB3VJDrxo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility \n",
        "numpy.random.seed(7) \n",
        "\n",
        "# load the dataset but only keep the top n words, zero the rest \n",
        "top_words = 5000 \n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h-XcwLJuDrx0",
        "colab_type": "code",
        "outputId": "59e73200-ecce-4302-874b-4722185feb2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "NUM_WORDS=1000 # only use top 1000 words\n",
        "INDEX_FROM=3   # word index offset\n",
        "word_to_id = keras.datasets.imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "print(' '.join(id_to_word[id] for id in X_train[0] ))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly <UNK> was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was <UNK> with us all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a1h3ZEFUDryF",
        "colab_type": "code",
        "outputId": "cefb083f-9913-4cae-dc61-5958a7da2635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "docs = ['Well done',\n",
        "\t\t'Decent',\n",
        "\t\t'Great idea',\n",
        "\t\t'Perfect',\n",
        "\t\t'Excellent']\n",
        "# integer encode the documents\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16, 17], [18], [43, 9], [36], [28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8kcu6G3YDryV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "VvCe1_emDryZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# truncate and pad the review sequences \n",
        "max_review_length = 500 \n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length) \n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C_9hXS7XDryk",
        "colab_type": "code",
        "outputId": "00e56d2a-d626-4415-c292-ed53f2fbacfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_train).head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4472</td>\n",
              "      <td>113</td>\n",
              "      <td>103</td>\n",
              "      <td>32</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>178</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>154</td>\n",
              "      <td>462</td>\n",
              "      <td>33</td>\n",
              "      <td>89</td>\n",
              "      <td>78</td>\n",
              "      <td>285</td>\n",
              "      <td>16</td>\n",
              "      <td>145</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>106</td>\n",
              "      <td>607</td>\n",
              "      <td>624</td>\n",
              "      <td>35</td>\n",
              "      <td>534</td>\n",
              "      <td>6</td>\n",
              "      <td>227</td>\n",
              "      <td>7</td>\n",
              "      <td>129</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>687</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3693</td>\n",
              "      <td>42</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>...</td>\n",
              "      <td>26</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>566</td>\n",
              "      <td>30</td>\n",
              "      <td>579</td>\n",
              "      <td>21</td>\n",
              "      <td>64</td>\n",
              "      <td>2574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>226</td>\n",
              "      <td>251</td>\n",
              "      <td>7</td>\n",
              "      <td>61</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5     6    7    8    9    ...    490  491  492  \\\n",
              "0    0    0    0    0    0    0     0    0    0    0  ...   4472  113  103   \n",
              "1    0    0    0    0    0    0     0    0    0    0  ...     52  154  462   \n",
              "2    0    0    0    0    0    0     0    0    0    0  ...    106  607  624   \n",
              "3  687   23    4    2    2    6  3693   42   38   39  ...     26   49    2   \n",
              "4    0    0    0    0    0    0     0    0    0    0  ...     19   14    5   \n",
              "\n",
              "   493  494  495  496  497  498   499  \n",
              "0   32   15   16    2   19  178    32  \n",
              "1   33   89   78  285   16  145    95  \n",
              "2   35  534    6  227    7  129   113  \n",
              "3   15  566   30  579   21   64  2574  \n",
              "4    2    6  226  251    7   61   113  \n",
              "\n",
              "[5 rows x 500 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "x7lSGh-6Dryy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ]
    },
    {
      "metadata": {
        "id": "0ezu23b4Dry2",
        "colab_type": "code",
        "outputId": "d9d7996f-dc8a-4555-aa0b-ba799cc2c6b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# create the model \n",
        "embedding_vector_length = 32 \n",
        "model = Sequential() \n",
        "model.add(Embedding(top_words, \n",
        "                    embedding_vector_length, \n",
        "                    input_length=max_review_length)) \n",
        "model.add(LSTM(100))\n",
        "lstm_output = model.output\n",
        "bayesian_dropout = Dropout(0.5)(lstm_output,\n",
        "                                training=True)\n",
        "#model.add(Flatten()) \n",
        "output = Dense(1, activation='sigmoid')(bayesian_dropout) \n",
        "\n",
        "model = Model([model.input], output) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zfwjl9FEPEsn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compile the model"
      ]
    },
    {
      "metadata": {
        "id": "Ghz6J8kVPEbV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ib_DR1jPRev",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Summarize the model"
      ]
    },
    {
      "metadata": {
        "id": "Z8BuBMVfPQ_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "5477691e-1ad5-4fc7-c5dd-1029ca00a7f5"
      },
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1_input (InputLaye (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lyaFbOpnPV56",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load pre-trained weights"
      ]
    },
    {
      "metadata": {
        "id": "ynxGfy_HQCKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_WEIGHTS = './Bayesian_LSTM.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ldFBduBxLSiU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.exists(MODEL_WEIGHTS):\n",
        "  model.load_weights(MODEL_WEIGHTS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2Lg72KPDrzK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ]
    },
    {
      "metadata": {
        "id": "fvpbpNaDDrzN",
        "colab_type": "code",
        "outputId": "658b63c0-d23a-44fe-fcc7-e885aa3c757e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_test, y_test), \n",
        "          epochs=3, \n",
        "          batch_size=64) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 501s 20ms/step - loss: 0.1659 - acc: 0.9383 - val_loss: 0.3599 - val_acc: 0.8689\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 500s 20ms/step - loss: 0.1565 - acc: 0.9432 - val_loss: 0.4198 - val_acc: 0.8620\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 500s 20ms/step - loss: 0.1376 - acc: 0.9491 - val_loss: 0.4074 - val_acc: 0.8607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f32cff50cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "MgJh4bftLIyn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save model weights"
      ]
    },
    {
      "metadata": {
        "id": "zeyXViL9LH0p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(MODEL_WEIGHTS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lEl9TiymDrzb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bayesian evaluation of the model"
      ]
    },
    {
      "metadata": {
        "id": "hPnHdwDpM97c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eval_steps = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4K69YCdXWF2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJdItor9Drze",
        "colab_type": "code",
        "outputId": "8b40fdb2-82a3-451f-eae5-af144c01cfdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Final evaluation of the model\n",
        "scores = []\n",
        "for eval_step in tqdm(range(eval_steps)):\n",
        "  score = model.evaluate(X_test, y_test, verbose=0) \n",
        "  scores.append(score[1])\n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (np.mean(scores*100)))\n",
        "print(\"Model uncertainty: %.2f%%\" % (np.std(scores*100)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  6%|▌         | 6/100 [06:48<1:46:38, 68.07s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9zH7d_skDrzs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate Bayesian predictions"
      ]
    },
    {
      "metadata": {
        "id": "GCntgp2UDrzw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bad = \"this movie was terrible and bad\"\n",
        "good = \"i really_ liked the movie and had fun\"\n",
        "neutral = \"I did not saw this coming in the movie?\"\n",
        "\n",
        "for input_string in [good,bad,neutral]:\n",
        "    review = input_string.lower()\n",
        "    review = re.sub(r\"[^A-Za-z0-9]+\", \" \", review)\n",
        "    tmp = []\n",
        "    for word in review.split(' '):\n",
        "        if word == '':\n",
        "          pass\n",
        "        else:\n",
        "          tmp.append(word_to_id[word])\n",
        "    tmp_padded = sequence.pad_sequences([tmp], maxlen=max_review_length)\n",
        "    sentiments = []\n",
        "    for eval_step in tqdm(range(eval_steps)):\n",
        "      sentiment = model.predict(array([tmp_padded][0]))[0][0]\n",
        "      sentiments.append(sentiment)\n",
        "    print(\"\\n%s ... \\nSentiment: %s ... \\nUncertainty: %s ...\" % (input_string, \n",
        "                                                                  np.mean(sentiments),\n",
        "                                                                  np.std(sentiments)))\n",
        "    time.sleep(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6AE-68yubSzw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Dh_39m0Drz-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "colab_mode = True\n",
        "download_weights = True\n",
        "if colab_mode and download_weights:\n",
        "  files.download(MODEL_WEIGHTS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukUHBH_UbPIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
