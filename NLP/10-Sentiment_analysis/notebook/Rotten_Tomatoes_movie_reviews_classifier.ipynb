{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rotten-Tomatoes_movie_reviews_classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEyH-OGNp-oF",
        "colab_type": "text"
      },
      "source": [
        "# Rotten Tomatoes movie review classifier using Keras and Tensorflow\n",
        "\n",
        "## Author: [Dr. Rahul Remanan](https://www.linkedin.com/in/rahulremanan) {rahul@moad.computer}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   [Kaggle Rotten Tomatoes datasets](https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only/data)\n",
        "* [This is a modified fork of the Kaggle kernel here](https://www.kaggle.com/nafisur/keras-models-lstm-cnn-gru-bidirectional-glove)\n",
        "\n",
        "\n",
        "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
        "\n",
        "## [Open this notebook in Google CoLab](https://colab.research.google.com/github/rahulremanan/python_tutorial/blob/master/NLP/10-Sentiment_analysis/notebook/Rotten_Tomatoes_movie_reviews_classifier.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNBXSE9fsHHX",
        "colab_type": "text"
      },
      "source": [
        "## Upload Kaggle authentication token\n",
        "\n",
        "Before downloading the data, ensure that the [terms of the competition](https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only/rules) is accepted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pneXAB2MEJ8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pKJHr6Pp27f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab_mode = True\n",
        "download_rawData = True\n",
        "setup = True\n",
        "\n",
        "ROOT_DIR = '/content/'\n",
        "WEIGHTS_FILENAME = 'RT_LSTM.h5'\n",
        "WEIGHTS_FILE = os.path.join(ROOT_DIR, WEIGHTS_FILENAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXdc1Igdr0EG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAF-6nCsrpbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if colab_mode and download_rawData:\n",
        "  files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l3D0SasuCEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if colab_mode and download_rawData:\n",
        "  ! mkdir /root/.kaggle/\n",
        "  ! mv /content/kaggle.json /root/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E712QDqys-fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if setup:\n",
        "  ! pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBJFWWGltrgI",
        "colab_type": "text"
      },
      "source": [
        "## Download the Rotten Tomatoes movie reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T71LYV58tfwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! kaggle competitions download -c movie-review-sentiment-analysis-kernels-only"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t0de0Cjt96Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "196G7hKXvVTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip -q /content/train.tsv.zip\n",
        "! unzip -q /content/test.tsv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOu7FtoJv2tc",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVpQb8-Svdv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#pd.set_option('display.max_colwidth',100)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ktgv8DO5wbXz",
        "colab_type": "text"
      },
      "source": [
        "## Read the train data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4JkLbd_wKru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('/content/train.tsv',sep='\\t')\n",
        "print(train.shape)\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygasEVElw01B",
        "colab_type": "text"
      },
      "source": [
        "## Summarize the training data\n",
        "\n",
        "### Get the [unqiue label values](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html) in the training data\n",
        "\n",
        "The sentiment labels are:\n",
        "\n",
        "* 0 - negative\n",
        "* 1 - somewhat negative\n",
        "* 2 - neutral\n",
        "* 3 - somewhat positive\n",
        "* 4 - positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMWejboZwWy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['Sentiment'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b14UVw0yQdH",
        "colab_type": "text"
      },
      "source": [
        "### Count the total number of training items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHdZQeJpwo32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train['Sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAew6xJIyVRc",
        "colab_type": "text"
      },
      "source": [
        "### Summarize the distribution of the sentiment classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9QWrJJuxZkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.groupby('Sentiment')['PhraseId'].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1maWswBykmY",
        "colab_type": "text"
      },
      "source": [
        "## Load test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB-7NR9Gx7Nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=pd.read_csv('/content/test.tsv',sep='\\t')\n",
        "print(test.shape)\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5BHmyNoyt72",
        "colab_type": "text"
      },
      "source": [
        "## Load the sample submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX2ZSfweyo7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub=pd.read_csv('/content/sampleSubmission.csv')\n",
        "sub.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtNWrsCrzEbF",
        "colab_type": "text"
      },
      "source": [
        "## Create sentiment column in the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtlPJB6Myw3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['Sentiment']=-999\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3Fi6uC4zkDE",
        "colab_type": "text"
      },
      "source": [
        "## Create a dataframe to store both train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wby5eJlSzL_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.concat([train,\n",
        "              test], ignore_index=True)\n",
        "print(df.shape)\n",
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA8wQheazd9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train,test\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSwhDgKUzwJE",
        "colab_type": "text"
      },
      "source": [
        "## Pre-process the movie review string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7U6s6EIzie0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
        "stemmer=SnowballStemmer('english')\n",
        "lemma=WordNetLemmatizer()\n",
        "from string import punctuation\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UADSGnoa0ilr",
        "colab_type": "text"
      },
      "source": [
        "### Download NLTK datasets\n",
        "\n",
        "Specify the NLTK corpus as 'punkt' or 'all'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu_idt0-0iMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqdpNyzwz2sE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_review(review_col):\n",
        "    review_corpus=[]\n",
        "    for i in range(0,len(review_col)):\n",
        "        review=str(review_col[i])\n",
        "        review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        #review=[stemmer.stem(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=' '.join(review)\n",
        "        review_corpus.append(review)\n",
        "    return review_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3J3Fsywz4DB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['clean_review']=clean_review(df.Phrase.values)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLQa4G0L0WfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train=df[df.Sentiment!=-999]\n",
        "print (df_train.shape)\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO-kNuAG1_5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test=df[df.Sentiment==-999]\n",
        "df_test.drop('Sentiment',axis=1,inplace=True)\n",
        "print(df_test.shape)\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSlXk0HE2Et5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOLWegg42V6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text=df_train.clean_review.values\n",
        "test_text=df_test.clean_review.values\n",
        "target=df_train.Sentiment.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7WuJq502hMP",
        "colab_type": "text"
      },
      "source": [
        "## Convert labels to categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgFS2l4j2fou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=to_categorical(target)\n",
        "print(train_text.shape,target.shape,y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z3-sAGM3B98",
        "colab_type": "text"
      },
      "source": [
        "## Create train-validation split for training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcYgunI-2ofp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_text,X_val_text,y_train,y_val=train_test_split(train_text,y,test_size=0.2,stratify=y,random_state=123)\n",
        "print(X_train_text.shape,y_train.shape)\n",
        "print(X_val_text.shape,y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2U8knkq3AwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_words=' '.join(X_train_text)\n",
        "all_words=word_tokenize(all_words)\n",
        "dist=FreqDist(all_words)\n",
        "num_unique_word=len(dist)\n",
        "num_unique_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vQuzXFa3aar",
        "colab_type": "text"
      },
      "source": [
        "## Finding the maximum length of the review in the training corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrKkega23LwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r_len=[]\n",
        "for text in X_train_text:\n",
        "    word=word_tokenize(text)\n",
        "    l=len(word)\n",
        "    r_len.append(l)\n",
        "    \n",
        "MAX_REVIEW_LEN=np.max(r_len)\n",
        "MAX_REVIEW_LEN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmFhMRcw3gB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = num_unique_word\n",
        "max_words = MAX_REVIEW_LEN\n",
        "batch_size = 128\n",
        "epochs = 3\n",
        "num_classes=y.shape[1]\n",
        "print ('Total number of sentiment classes: {} ...'.format(num_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX0rspAA4FkD",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize the input text\n",
        "\n",
        "Tokenizing using [Keras text pre-processor](https://keras.io/preprocessing/text/). This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNpXDm2q3_PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train_text))\n",
        "X_train = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_val = tokenizer.texts_to_sequences(X_val_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcy6-c0R5Vx1",
        "colab_type": "text"
      },
      "source": [
        "## Padding the input text for a fixed input length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-tkw_SW5RYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "print(X_train.shape,X_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cp_Xxxe7eGW",
        "colab_type": "text"
      },
      "source": [
        "## The role of [embedding layer in a neural network](https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.  One-hot encoded vectors are high-dimensional and sparse. Letâ€™s assume that we are doing Natural Language Processing (NLP) and have a dictionary of 2000 words. This means that, when using one-hot encoding, each word will be represented by a vector containing 2000 integers. And 1999 of these integers are zeros. In a big dataset this approach is not computationally efficient.\n",
        "\n",
        "2.   The vectors of each embedding get updated while training the neural network. If you have seen the image at the top of this post you can see how similarities between words can be found in a multi-dimensional space. This allows us to visualize relationships between words, but also between everything that can be turned into a vector through an embedding layer.\n",
        "\n",
        "[Read more about keras embedding layer](https://keras.io/layers/embeddings/#embedding)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG1s_IaX9taM",
        "colab_type": "text"
      },
      "source": [
        "## Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_A_4VFB5auL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_LSTM():\n",
        "  model=Sequential()\n",
        "  model.add(Embedding(max_features,100,mask_zero=True))\n",
        "  model.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
        "  model.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "  model.add(Dense(4096, activation='tanh'))\n",
        "  model.add(Dense(num_classes,activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7S6WvsR8JBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model_LSTM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFu_COGh8Bbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeMWqxAy8Nxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "history1=model.fit(X_train, \n",
        "                    y_train, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=epochs, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX0QIIVUDkGI",
        "colab_type": "text"
      },
      "source": [
        "## Save the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nym5ngCrAtMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvVQyYSmG3Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQwYht-MDnKq",
        "colab_type": "text"
      },
      "source": [
        "## Load model weights from weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXBNURGaA2Cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  model.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded model weights from: {} ...'.format(WEIGHTS_FILE))\n",
        "except:\n",
        "  print ('No model weights file: {} found ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuQWOVRa-ZQY",
        "colab_type": "text"
      },
      "source": [
        "## Running model inference on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOGAqbqW-Hi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = tokenizer.texts_to_sequences(test_text)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NpvSek48wB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = np.asarray([list(X_test[1])])\n",
        "y_pred_LSTM=model.predict(input_sequence,verbose=1)\n",
        "print ('Input string: {} ...'.format(test_text[1]))\n",
        "print (np.argmax(y_pred_LSTM))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0nmqq6kDRTF",
        "colab_type": "text"
      },
      "source": [
        "## Run inference for custom user input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doT362JZCE3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_string = ['This movie was horrible']\n",
        "input_text = tokenizer.texts_to_sequences(input_string)\n",
        "input_sequence = sequence.pad_sequences(input_text, maxlen=max_words)\n",
        "y_pred_LSTM=model.predict(input_sequence,verbose=1)\n",
        "print ('Input string: {} ...'.format(input_string))\n",
        "print (np.argmax(y_pred_LSTM))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmVFhqB3AF0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_string = ['This movie was great']\n",
        "input_text = tokenizer.texts_to_sequences(input_string)\n",
        "input_sequence = sequence.pad_sequences(input_text, maxlen=max_words)\n",
        "y_pred_LSTM=model.predict(input_sequence,verbose=1)\n",
        "print ('Input string: {} ...'.format(input_string))\n",
        "print (np.argmax(y_pred_LSTM))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsV3Za7s_6po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}